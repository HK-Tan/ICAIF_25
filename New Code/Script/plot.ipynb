{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: c:\\Users\\james\\ICAIF_25\\New Code\\Script\n",
      "Added to sys.path for custom modules: c:\\Users\\james\\ICAIF_25\\New Code\\Modules\n",
      "Data loaded and cleaned. Sample (first 5 rows/cols):\n",
      "ticker            AA       ABM       ABT       ADI       ADM\n",
      "2000-01-03 -0.013042 -0.009188 -0.007117 -0.036071  0.000000\n",
      "2000-01-04  0.010043  0.012346 -0.012786 -0.044261  0.005277\n",
      "2000-01-05  0.047628 -0.006192  0.011111  0.014493 -0.015915\n",
      "2000-01-06 -0.011713  0.000000  0.032553 -0.027719  0.010695\n",
      "2000-01-07 -0.016118  0.003091  0.028573  0.033654  0.005249\n",
      "Shape of the cleaned data: (5279, 663)\n",
      "\n",
      "===== Running Parallelized Grid Search Evaluation (Simplified Edges) =====\n",
      "Phase 1: Preparing hyperparameter evaluation tasks...\n",
      "Phase 1: Running 540 hyperparameter PNL calculations in parallel...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "current_working_dir = os.getcwd()\n",
    "print(f\"Current Working Directory: {current_working_dir}\")\n",
    "project_root = os.path.dirname(current_working_dir)\n",
    "modules_path = os.path.join(project_root, 'Modules')\n",
    "if modules_path not in sys.path:\n",
    "    sys.path.append(modules_path)\n",
    "    print(f\"Added to sys.path for custom modules: {modules_path}\")\n",
    "data_folder_path = os.path.join(project_root, 'Data')\n",
    "data_file_name = \"OPCL_20000103_20201231.csv\"\n",
    "data_file_path = os.path.join(data_folder_path, data_file_name)\n",
    "\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from parallelized_runs import run_sliding_window_var_evaluation_vectorized\n",
    "import multiprocessing\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='statsmodels')\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "try:\n",
    "    from signet.cluster import Cluster\n",
    "except ImportError:\n",
    "    print(\"Signet package not found. Attempting to install from GitHub...\")\n",
    "    try:\n",
    "        import subprocess\n",
    "        subprocess.check_call(\n",
    "            [sys.executable, \"-m\", \"pip\", \"install\", \"git+https://github.com/alan-turing-institute/SigNet.git\"]\n",
    "        )\n",
    "        from signet.cluster import Cluster\n",
    "        print(\"Signet package installed successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error installing Signet package: {e}\")\n",
    "        print(\"Please install it manually: pip install git+https://github.com/alan-turing-institute/SigNet.git\")\n",
    "\n",
    "# Main execution block\n",
    "if __name__ == '__main__':\n",
    "    multiprocessing.freeze_support()\n",
    "\n",
    "    df = pd.read_csv(data_file_path) # Assumes file exists and is readable\n",
    "\n",
    "    df.set_index('ticker', inplace=True)\n",
    "    df.columns = pd.to_datetime(df.columns.str.lstrip('X'), format='%Y%m%d').strftime('%Y-%m-%d')\n",
    "    df_cleaned = df.dropna().transpose() # Assumes dropna results in non-empty df\n",
    "    df_cleaned.index = pd.to_datetime(df_cleaned.index)\n",
    "    print(\"Data loaded and cleaned. Sample (first 5 rows/cols):\")\n",
    "    print(df_cleaned.iloc[0:5,0:5])\n",
    "    print(f\"Shape of the cleaned data: {df_cleaned.shape}\")\n",
    "\n",
    "    ##################################################################### PARAMETERS #####################################################################\n",
    "    initial_lookback_len = 252\n",
    "    evaluation_len = 20\n",
    "    num_clusters_config = [50, 100, 150]\n",
    "    cluster_method_config = 'SPONGE'\n",
    "    sigma_config = 0.01\n",
    "    num_windows_config = 20 # Ensure df_cleaned has enough data for this: (num_windows_config-1)*eval_len + initial_lookback_len + eval_len\n",
    "    repetitions = 3\n",
    "    var_orders_config = [5, 7, 9] # Ensure initial_lookback_len - evaluation_len > max(var_orders_config)\n",
    "    ####################################################################################################################################################\n",
    "    # Basic check for parameter sanity (example)\n",
    "    if not (initial_lookback_len - evaluation_len > max(var_orders_config)):\n",
    "        raise ValueError(\"Insufficient lookback length for hyperparameter evaluation based on var_orders_config and evaluation_len.\")\n",
    "    if not (df_cleaned.shape[0] >= (num_windows_config -1) * evaluation_len + initial_lookback_len + evaluation_len):\n",
    "        raise ValueError(\"Insufficient total data for the specified number of windows, lookback, and evaluation lengths.\")\n",
    "\n",
    "\n",
    "    all_lags_combined_pnl = []\n",
    "    sample_forecast_details = {}\n",
    "\n",
    "    historical_data = df_cleaned.astype(float)\n",
    "\n",
    "    print(f\"\\n===== Running Parallelized Grid Search Evaluation (Simplified Edges) =====\")\n",
    "    results_dict = run_sliding_window_var_evaluation_vectorized(\n",
    "        asset_returns_df=historical_data,\n",
    "        initial_lookback_len=initial_lookback_len,\n",
    "        eval_len=evaluation_len,\n",
    "        repetitions=repetitions,\n",
    "        n_clusters_config=num_clusters_config,\n",
    "        cluster_method=cluster_method_config,\n",
    "        var_order_config=var_orders_config,\n",
    "        sigma_intra_cluster=sigma_config,\n",
    "        num_windows_config=num_windows_config,\n",
    "        store_sample_forecasts=True,\n",
    "        run_naive_var_comparison=True\n",
    "    )\n",
    "\n",
    "    all_lags_combined_pnl.extend(results_dict['cluster_avg_pnl_list'])\n",
    "    if 'naive_avg_pnl_list' in results_dict: # Still check as it's optional\n",
    "        all_lags_combined_pnl.extend(results_dict['naive_avg_pnl_list'])\n",
    "\n",
    "    sample_forecast_details['forecast'] = results_dict.get('sample_forecast_cluster')\n",
    "    sample_forecast_details['actual'] = results_dict.get('sample_actual_cluster')\n",
    "    sample_forecast_details['window_idx'] = results_dict.get('sample_window_idx_cluster')\n",
    "    sample_forecast_details['method'] = 'Clustered VAR (Parallel Grid Search, Simplified)'\n",
    "\n",
    "    df_all_pnl_by_lag_method = pd.DataFrame(all_lags_combined_pnl) # Assumes all_lags_combined_pnl is not empty\n",
    "\n",
    "    print(\"\\n--- Grid Search Completed (Parallelized, Simplified) ---\")\n",
    "    print(\"\\nAverage Window PNL per Selected Lag Order and Method:\")\n",
    "    pivot_index_cols = ['VAR_Order']\n",
    "    if 'N_Clusters' in df_all_pnl_by_lag_method.columns and \\\n",
    "        any(item['Method'] == 'Clustered VAR' for item in all_lags_combined_pnl if 'Method' in item):\n",
    "        pivot_index_cols.append('N_Clusters')\n",
    "\n",
    "    avg_pnl_pivot = df_all_pnl_by_lag_method.pivot_table(\n",
    "        index=pivot_index_cols,\n",
    "        columns='Method',\n",
    "        values='Avg_Window_PNL',\n",
    "        aggfunc='mean'\n",
    "    )\n",
    "    print(avg_pnl_pivot)\n",
    "\n",
    "    # Plotting (assumes data is present for plots)\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    sns.boxplot(x='VAR_Order', y='Avg_Window_PNL', hue='Method', data=df_all_pnl_by_lag_method)\n",
    "    plt.title(f'Distribution of Average Window PNL by Selected VAR Lag Order and Method')\n",
    "    plt.xlabel('Selected VAR Lag Order for Window')\n",
    "    plt.ylabel(f'Average Window PNL')\n",
    "    plt.legend(title='Forecast Method')\n",
    "    plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    sample_forecast = sample_forecast_details['forecast']\n",
    "    sample_actual = sample_forecast_details['actual']\n",
    "    stored_window_idx = sample_forecast_details.get('window_idx') # Removed \"N/A\" default\n",
    "    method_name = sample_forecast_details.get('method')\n",
    "\n",
    "    title_var_order, title_n_clusters = \"N/A\", \"N/A\" # Keep N/A for title if not found\n",
    "    # Simplified logic for getting title parameters\n",
    "    sample_window_data_rows = df_all_pnl_by_lag_method[\n",
    "        (df_all_pnl_by_lag_method['Window_ID'] == stored_window_idx) &\n",
    "        (df_all_pnl_by_lag_method['Method'] == 'Clustered VAR')\n",
    "    ]\n",
    "    if not sample_window_data_rows.empty: # Still need this check for robustness of title\n",
    "        row = sample_window_data_rows.iloc[0]\n",
    "        title_var_order = row['VAR_Order']\n",
    "        if 'N_Clusters' in row.index:\n",
    "            title_n_clusters = row['N_Clusters']\n",
    "\n",
    "    print(f\"\\n--- Plotting Predictions vs. Actuals for Sample Window {stored_window_idx + 1 if isinstance(stored_window_idx, int) else stored_window_idx} ({method_name}) ---\")\n",
    "    print(f\"Params for this sample: VAR Lag={title_var_order}, N_Clusters={title_n_clusters}\")\n",
    "\n",
    "    # Assumes sample_forecast and sample_actual are valid DataFrames with columns\n",
    "    num_items_to_plot = min(3, sample_forecast.shape[1], sample_actual.shape[1])\n",
    "    for i in range(num_items_to_plot):\n",
    "        item_name = sample_forecast.columns[i]\n",
    "        # Assumes item_name is in sample_actual.columns\n",
    "        plt.figure(figsize=(14, 7))\n",
    "        actual_plot_data = sample_actual[item_name].values[title_var_order-1:]\n",
    "        forecast_plot_data = sample_forecast[item_name].values\n",
    "        min_plot_len = min(len(actual_plot_data), len(forecast_plot_data))\n",
    "\n",
    "        sns.lineplot(data=actual_plot_data[:min_plot_len], label=f'Actual - {item_name}', marker='o', linestyle='-')\n",
    "        sns.lineplot(data=forecast_plot_data[:min_plot_len], label=f'Forecast - {item_name}', marker='x', linestyle='--')\n",
    "        plt.title(f'Prediction vs. Actual for {item_name} (Window {stored_window_idx + 1 if isinstance(stored_window_idx, int) else stored_window_idx}, VAR Lag {title_var_order}, N_Clust {title_n_clusters})')\n",
    "        plt.xlabel('Forecast Step')\n",
    "        plt.ylabel('Return Value (Cluster)')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "16A",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
