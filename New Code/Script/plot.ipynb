{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "current_working_dir = os.getcwd()\n",
    "print(f\"Current Working Directory: {current_working_dir}\")\n",
    "project_root = os.path.dirname(current_working_dir)\n",
    "modules_path = os.path.join(project_root, 'Modules')\n",
    "if modules_path not in sys.path:\n",
    "    sys.path.append(modules_path)\n",
    "    print(f\"Added to sys.path for custom modules: {modules_path}\")\n",
    "data_folder_path = os.path.join(project_root, 'Data')\n",
    "data_file_name = \"OPCL_20000103_20201231.csv\"   # Is this log(returns) or just returns\n",
    "data_file_path = os.path.join(data_folder_path, data_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from parallelized_runs import run_sliding_window_var_evaluation_vectorized\n",
    "import multiprocessing\n",
    "import subprocess\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='statsmodels')\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "try:\n",
    "    from signet.cluster import Cluster\n",
    "except ImportError:\n",
    "    print(\"Signet package not found. Attempting to install from GitHub...\")\n",
    "    try:\n",
    "        subprocess.check_call(\n",
    "            [sys.executable, \"-m\", \"pip\", \"install\", \"git+https://github.com/alan-turing-institute/SigNet.git\"]\n",
    "        )\n",
    "        # This part of the code should go first since importing parallelized_runs already requires the signet package\n",
    "        from signet.cluster import Cluster\n",
    "        print(\"Signet package installed successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error installing Signet package: {e}\")\n",
    "        print(\"Please install it manually: pip install git+https://github.com/alan-turing-institute/SigNet.git\")\n",
    "\n",
    "# !pip install padasip\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"sktime\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiprocessing.freeze_support()\n",
    "\n",
    "df = pd.read_csv(data_file_path) # Assumes file exists and is readable\n",
    "\n",
    "df.set_index('ticker', inplace=True)\n",
    "df.columns = pd.to_datetime(df.columns.str.lstrip('X'), format='%Y%m%d').strftime('%Y-%m-%d')\n",
    "df_cleaned = df.dropna().transpose() # Assumes dropna results in non-empty df\n",
    "df_cleaned.index = pd.to_datetime(df_cleaned.index)\n",
    "print(\"Data loaded and cleaned. Sample (first 5 rows/cols):\")\n",
    "print(df_cleaned.iloc[0:5,0:5])\n",
    "print(f\"Shape of the cleaned data: {df_cleaned.shape}\")\n",
    "\n",
    "train_data_ratio = 16/21\n",
    "split_index = int(train_data_ratio * len(df_cleaned))\n",
    "df_train_dataset = df_cleaned.iloc[:split_index]\n",
    "df_test_dataset = df_cleaned.iloc[split_index:]\n",
    "\n",
    "##################################################################### PARAMETERS #####################################################################\n",
    "# I think we also need a train-test split here\n",
    "initial_lookback_len = 252\n",
    "evaluation_len = 20 # I feel like this could be 252? Refer to our discussion\n",
    "# num_clusters_config = [5] # Why 50, 100, 150?\n",
    "num_clusters_config = [3,5,8,10,11,12,15,20]\n",
    "num_clusters_config = [5,11,20]\n",
    "cluster_method_config = 'SPONGE_sym'\n",
    "sigma_config = 0.01 # This is a hyperparameter for SPONGE, ... hyperparameter tuning? Usual: 0.01 (less sparse), 0.1 (more sparse)\n",
    "num_windows_config = 192 # Ensure df_cleaned has enough data for this\n",
    "repetitions = 1 # This should not be \\\"multiplied\\\" for the number of runs, if cluster initialization is to be refreshed every window.\n",
    "var_orders_config = [1,2,3,4,5,10,20] # Ensure initial_lookback_len - evaluation_len > max(var_orders_config)\n",
    "var_orders_config = [1,5,10,20]\n",
    "# var_orders_config = [5] # Ensure initial_lookback_len - evaluation_len > max(var_orders_config)\n",
    "max_threads = 12 # Must be tuned to your PC's CPU/RAM limitations\n",
    "####################################################################################################################################################\n",
    "# Basic check for parameter sanity (example)\n",
    "if not (initial_lookback_len - evaluation_len > max(var_orders_config)):\n",
    "    raise ValueError(\"Insufficient lookback length for hyperparameter evaluation based on var_orders_config and evaluation_len.\")\n",
    "if not (df_cleaned.shape[0] >= (num_windows_config) * evaluation_len + initial_lookback_len):\n",
    "    raise ValueError(\"Insufficient total data for the specified number of windows, lookback, and evaluation lengths.\")\n",
    "\n",
    "\n",
    "all_lags_combined_pnl = []\n",
    "sample_forecast_details = {}\n",
    "\n",
    "\n",
    "print(f\"\\n===== Running Parallelized Grid Search Evaluation (Simplified Edges) =====\")\n",
    "results_dict = run_sliding_window_var_evaluation_vectorized(\n",
    "    asset_returns_df=df_train_dataset,\n",
    "    initial_lookback_len=initial_lookback_len,\n",
    "    eval_len=evaluation_len,\n",
    "    repetitions=repetitions,\n",
    "    n_clusters_config=num_clusters_config,\n",
    "    cluster_method=cluster_method_config,\n",
    "    var_order_config=var_orders_config,\n",
    "    sigma_intra_cluster=sigma_config,\n",
    "    # num_windows_config=num_windows_config,\n",
    "    # num_windows_config=64,\n",
    "    num_windows_config=180,\n",
    "    store_sample_forecasts=True,\n",
    "    run_naive_var_comparison=True,\n",
    "    max_threads=max_threads\n",
    ")\n",
    "\n",
    "all_lags_combined_pnl.extend(results_dict['cluster_avg_pnl_list'])\n",
    "if 'naive_avg_pnl_list' in results_dict: # Still check as it's optional\n",
    "    all_lags_combined_pnl.extend(results_dict['naive_avg_pnl_list'])\n",
    "\n",
    "sample_forecast_details['forecast'] = results_dict.get('sample_forecast_cluster')\n",
    "sample_forecast_details['actual'] = results_dict.get('sample_actual_cluster')\n",
    "sample_forecast_details['window_idx'] = results_dict.get('sample_window_idx_cluster')\n",
    "sample_forecast_details['method'] = 'Clustered VAR (Parallel Grid Search, Simplified)'\n",
    "\n",
    "df_all_pnl_by_lag_method = pd.DataFrame(all_lags_combined_pnl) # Assumes all_lags_combined_pnl is not empty\n",
    "\n",
    "print(\"\\n--- Grid Search Completed (Parallelized, Simplified) ---\")\n",
    "print(\"\\nAverage Window PNL per Selected Lag Order and Method:\")\n",
    "pivot_index_cols = ['VAR_Order']\n",
    "if 'N_Clusters' in df_all_pnl_by_lag_method.columns and \\\n",
    "    any(item['Method'] == 'Clustered VAR' for item in all_lags_combined_pnl if 'Method' in item):\n",
    "    pivot_index_cols.append('N_Clusters')\n",
    "\n",
    "avg_pnl_pivot = df_all_pnl_by_lag_method.pivot_table(\n",
    "    index=pivot_index_cols,\n",
    "    columns='Method',\n",
    "    values='Avg_Window_PNL',\n",
    "    aggfunc='mean'\n",
    ")\n",
    "print(avg_pnl_pivot)\n",
    "\n",
    "# Plotting (assumes data is present for plots)\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.boxplot(x='VAR_Order', y='Avg_Window_PNL', hue='Method', data=df_all_pnl_by_lag_method)\n",
    "plt.title(f'Distribution of Average Window PNL by Selected VAR Lag Order and Method')\n",
    "plt.xlabel('Selected VAR Lag Order for Window')\n",
    "plt.ylabel(f'Average Window PNL')\n",
    "plt.legend(title='Forecast Method')\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "sample_forecast = sample_forecast_details['forecast']\n",
    "sample_actual = sample_forecast_details['actual']\n",
    "stored_window_idx = sample_forecast_details.get('window_idx') # Removed \"N/A\" default\n",
    "method_name = sample_forecast_details.get('method')\n",
    "\n",
    "title_var_order, title_n_clusters = \"N/A\", \"N/A\" # Keep N/A for title if not found\n",
    "# Simplified logic for getting title parameters\n",
    "sample_window_data_rows = df_all_pnl_by_lag_method[\n",
    "    (df_all_pnl_by_lag_method['Window_ID'] == stored_window_idx) &\n",
    "    (df_all_pnl_by_lag_method['Method'] == 'Clustered VAR')\n",
    "]\n",
    "if not sample_window_data_rows.empty: # Still need this check for robustness of title\n",
    "    row = sample_window_data_rows.iloc[0]\n",
    "    title_var_order = row['VAR_Order']\n",
    "    if 'N_Clusters' in row.index:\n",
    "        title_n_clusters = row['N_Clusters']\n",
    "\n",
    "print(f\"\\n--- Plotting Predictions vs. Actuals for Sample Window {stored_window_idx + 1 if isinstance(stored_window_idx, int) else stored_window_idx} ({method_name}) ---\")\n",
    "print(f\"Params for this sample: VAR Lag={title_var_order}, N_Clusters={title_n_clusters}\")\n",
    "\n",
    "# Assumes sample_forecast and sample_actual are valid DataFrames with columns\n",
    "# num_items_to_plot = min(3, sample_forecast.shape[1], sample_actual.shape[1])\n",
    "# for i in range(num_items_to_plot):\n",
    "#     item_name = sample_forecast.columns[i]\n",
    "#     # Assumes item_name is in sample_actual.columns\n",
    "#     plt.figure(figsize=(14, 7))\n",
    "#     actual_plot_data = sample_actual[item_name].values[title_var_order-1:]\n",
    "#     forecast_plot_data = sample_forecast[item_name].values\n",
    "#     min_plot_len = min(len(actual_plot_data), len(forecast_plot_data))\n",
    "\n",
    "#     sns.lineplot(data=actual_plot_data[:min_plot_len], label=f'Actual - {item_name}', marker='o', linestyle='-')\n",
    "#     sns.lineplot(data=forecast_plot_data[:min_plot_len], label=f'Forecast - {item_name}', marker='x', linestyle='--')\n",
    "#     plt.title(f'Prediction vs. Actual for {item_name} (Window {stored_window_idx + 1 if isinstance(stored_window_idx, int) else stored_window_idx}, VAR Lag {title_var_order}, N_Clust {title_n_clusters})')\n",
    "#     plt.xlabel('Forecast Step')\n",
    "#     plt.ylabel('Return Value (Cluster)')\n",
    "#     plt.legend()\n",
    "#     plt.grid(True)\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_dict.keys())\n",
    "\n",
    "print(results_dict['sample_forecast_cluster'])\n",
    "print(results_dict['sample_actual_cluster'])\n",
    "\n",
    "print(len(results_dict['cluster_avg_pnl_list']))\n",
    "print(results_dict['cluster_avg_pnl_list'][0])\n",
    "# print(results_dict['sample_forecast_cluster'])\n",
    "# print(results_dict['sample_actual_cluster'])\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open(\"Saved_Runs/long_run_results_dict.pkl\", \"wb\") as file:\n",
    "    pickle.dump(results_dict, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print Training PnL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS THE CODE FOR PLOTTING PNL AND RETURNS AND VAR/CLUSTER ORDERS\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Your data list\n",
    "data = results_dict['cluster_avg_pnl_list']\n",
    "\n",
    "# Extract fields\n",
    "window_ids = [d['Window_ID'] for d in data]\n",
    "avg_pnls = [d['Avg_Window_PNL'] for d in data]\n",
    "n_clusters = [d['N_Clusters'] for d in data]\n",
    "var_orders = [d['VAR_Order'] for d in data]\n",
    "\n",
    "# Compute cumulative return\n",
    "cumulative_returns = np.cumprod([1 + r for r in avg_pnls])\n",
    "\n",
    "# Create plot\n",
    "fig, axs = plt.subplots(2, 1, figsize=(12, 8), sharex=True)\n",
    "\n",
    "# Plot 1: Avg PNL and cumulative return\n",
    "ax1 = axs[0]\n",
    "line1 = ax1.plot(window_ids, avg_pnls, marker='o', label=\"Avg Window PNL\")\n",
    "ax1.set_ylabel(\"Avg Window PNL\")\n",
    "ax1.set_title(\"Average PNL and Cumulative Return per Window\")\n",
    "\n",
    "# Second y-axis for cumulative return\n",
    "ax2 = ax1.twinx()\n",
    "line2 = ax2.plot(window_ids, cumulative_returns, color='green', linestyle='--', label=\"Cumulative Return\")\n",
    "ax2.set_ylabel(\"Cumulative Return\")\n",
    "\n",
    "# Combine legends from both axes\n",
    "lines = line1 + line2\n",
    "labels = [l.get_label() for l in lines]\n",
    "ax1.legend(lines, labels, loc=\"upper right\")\n",
    "\n",
    "# Plot 2: Bar chart of N_Clusters and VAR_Order\n",
    "bar_width = 0.4\n",
    "x = range(len(window_ids))\n",
    "axs[1].bar([i - bar_width / 2 for i in x], n_clusters, width=bar_width, label='N_Clusters')\n",
    "axs[1].bar([i + bar_width / 2 for i in x], var_orders, width=bar_width, label='VAR_Order')\n",
    "axs[1].set_ylabel(\"Value\")\n",
    "axs[1].set_xlabel(\"Window ID\")\n",
    "axs[1].set_title(\"N_Clusters and VAR_Order per Window\")\n",
    "# axs[1].set_xticks(x)\n",
    "# axs[1].set_xticklabels(window_ids)\n",
    "axs[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append 1 lookback length from the end of the train dataset to the test dataset\n",
    "df_test_dataset = pd.concat([df_train_dataset.iloc[-1*initial_lookback_len:], df_test_dataset], axis=0)\n",
    "\n",
    "print(f\"\\n===== Running Parallelized Grid Search Evaluation (Simplified Edges) =====\")\n",
    "results_dict = run_sliding_window_var_evaluation_vectorized(\n",
    "    asset_returns_df=df_test_dataset,\n",
    "    initial_lookback_len=initial_lookback_len,\n",
    "    eval_len=evaluation_len,\n",
    "    repetitions=repetitions,\n",
    "    n_clusters_config=num_clusters_config,\n",
    "    cluster_method=cluster_method_config,\n",
    "    var_order_config=var_orders_config,\n",
    "    sigma_intra_cluster=sigma_config,\n",
    "    # num_windows_config=num_windows_config,\n",
    "    # num_windows_config=20,\n",
    "    num_windows_config=60,\n",
    "    store_sample_forecasts=True,\n",
    "    run_naive_var_comparison=True,\n",
    "\n",
    "    max_threads=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_pnl_pivot = df_all_pnl_by_lag_method.pivot_table(\n",
    "    index=pivot_index_cols,\n",
    "    columns='Method',\n",
    "    values='Avg_Window_PNL',\n",
    "    aggfunc='mean'\n",
    ")\n",
    "print(avg_pnl_pivot)\n",
    "\n",
    "# Plotting (assumes data is present for plots)\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.boxplot(x='VAR_Order', y='Avg_Window_PNL', hue='Method', data=df_all_pnl_by_lag_method)\n",
    "plt.title(f'Distribution of Average Window PNL by Selected VAR Lag Order and Method')\n",
    "plt.xlabel('Selected VAR Lag Order for Window')\n",
    "plt.ylabel(f'Average Window PNL')\n",
    "plt.legend(title='Forecast Method')\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "16A",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
