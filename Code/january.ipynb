{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ÉTAPE 0** : préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no NaN values in the dataframe\n"
     ]
    }
   ],
   "source": [
    "import process \n",
    "import pandas as pd\n",
    "\n",
    "# Nail path : '/Users/khelifanail/Documents/GitHub/Portfolio_clustering_project/Data/DATA_Statapp.csv'\n",
    "# Jerome path : 'C:\\Users\\33640\\OneDrive\\Documents\\GitHub\\Portfolio_clustering_project\\Data\\DATA_Statapp.csv'\n",
    "# Mohamed path : '/Users/khelifanail/Documents/GitHub/Portfolio_clustering_project/Data/DATA_Statapp.csv'\n",
    "df = pd.read_csv('/Users/khelifanail/Documents/GitHub/Portfolio_clustering_project/Data/DATA_Statapp.csv')\n",
    "\n",
    "# Apply conversion function to 'open' and 'close' columns\n",
    "df['open'] = df['open'].apply(process.safe_literal_eval)\n",
    "df['close'] = df['close'].apply(process.safe_literal_eval)\n",
    "\n",
    "# Calculate returns for each line\n",
    "df['return'] = df.apply(lambda row: [(close - open) / open for open, close in zip(row['open'], row['close'])], axis=1)\n",
    "\n",
    "new_df = df[['ticker', 'return']] # create a new data frame with the column ticker and return \n",
    "\n",
    "# Créons le DataFrame à partir des listes dans 'return'\n",
    "# On suppose ici que 'new_df' est déjà défini et contient la colonne 'return'\n",
    "\n",
    "# Convertir chaque liste dans la colonne 'return' en plusieurs colonnes dans le nouveau DataFrame\n",
    "returns_df = pd.DataFrame(new_df['return'].tolist())\n",
    "\n",
    "# Ajouter la colonne 'ticker' du 'new_df' au début de 'returns_df'\n",
    "returns_df.insert(0, 'ticker', new_df['ticker'])\n",
    "\n",
    "# Renommer les colonnes pour refléter qu'elles sont des rendements\n",
    "returns_df.columns = ['ticker'] + [f'return_{i}' for i in range(len(returns_df.columns) - 1)]\n",
    "\n",
    "df_cleaned = process.remove_rows_with_nan(returns_df)\n",
    "df_cleaned.reset_index(drop=True, inplace=True)\n",
    "\n",
    "process.check_nan_inf(df_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ÉTAPE 1** : Phase d'entraînement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Obtention de la matrice de corrélation des actifs sur une fenêtre arrière de 30 jours (1 mois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khelifanail/Documents/GitHub/Portfolio_clustering_project/Code/process.py:46: FutureWarning:\n",
      "\n",
      "DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "\n",
      "/Users/khelifanail/Documents/GitHub/Portfolio_clustering_project/Code/process.py:47: FutureWarning:\n",
      "\n",
      "DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning:\n",
      "\n",
      "The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "\n"
     ]
    }
   ],
   "source": [
    "L = 365\n",
    "W = process.training_phase(lookback_window=L, df_cleaned=df_cleaned, number_of_clusters=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def portfolio_return(evaluation_window):\n",
    "    evaluation_set = df_cleaned.iloc[:, L+1:L+1+evaluation_window]\n",
    "\n",
    "    evaluation_set = df_cleaned.iloc[:, L+1:L+1+evaluation_window]\n",
    "\n",
    "    portfolio_return = pd.DataFrame(index=evaluation_set.columns, columns=['portfolio return'], data=np.zeros(len(evaluation_set.columns)))\n",
    "\n",
    "    for elem1 in portfolio_return.index:\n",
    "        for elem2 in W:\n",
    "            portfolio_return.loc[str(elem1), 'portfolio return'] += elem2[1]*evaluation_set.loc[elem2[0], str(elem1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sharpe_and_PnL(portfolio_return):\n",
    "    portfolio_return = np.array(portfolio_return)\n",
    "\n",
    "    # Calcul du rendement moyen du portefeuille\n",
    "    Rp = np.mean(portfolio_return)\n",
    "\n",
    "    # Calcul de l'écart type du portefeuille\n",
    "    sigma_p = np.std(portfolio_return)\n",
    "\n",
    "    # Taux sans risque (ou rendement moyen du marché)\n",
    "    Rf = 0.02  # Remplacez par le taux sans risque ou le rendement moyen du marché approprié\n",
    "\n",
    "    # Calcul du Sharpe ratio\n",
    "    SR = (Rp - Rf) / sigma_p\n",
    "\n",
    "    # Calcul des PNL\n",
    "    PNL = np.cumsum(portfolio_return)\n",
    "\n",
    "    return SR, PNL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "def plot_PnL(SR, PNL):\n",
    "\n",
    "    # Création du graphique\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Ajout de la trace pour les PNL\n",
    "    fig.add_trace(go.Scatter(x=np.arange(31, 61), y=PNL, mode='lines', name='PNL'))\n",
    "\n",
    "    # Ajout d'une ligne pour le Sharpe ratio\n",
    "    fig.add_shape(\n",
    "        type='line',\n",
    "        x0=31, x1=60, y0=0, y1=0,\n",
    "        line=dict(color='red', width=2),\n",
    "        opacity=0.7,\n",
    "        name='Sharpe Ratio'\n",
    "    )\n",
    "\n",
    "    # Ajout d'une annotation pour le Sharpe ratio\n",
    "    fig.add_annotation(\n",
    "        x=45,\n",
    "        y=PNL[-1],\n",
    "        text=f'Sharpe Ratio: {SR:.4f}',\n",
    "        showarrow=True,\n",
    "        arrowhead=2,\n",
    "        arrowsize=1,\n",
    "        arrowwidth=2,\n",
    "        arrowcolor='red',\n",
    "        font=dict(size=10),\n",
    "        bordercolor='red',\n",
    "        borderwidth=2,\n",
    "        bgcolor='white',\n",
    "        opacity=0.8\n",
    "    )\n",
    "\n",
    "    # Mise en forme du graphique\n",
    "    fig.update_layout(\n",
    "        title='Évolution des PNL et Sharpe Ratio',\n",
    "        xaxis_title='Période',\n",
    "        yaxis_title='PNL Cumulatif',\n",
    "        legend=dict(x=0, y=1),\n",
    "        template='plotly_white'\n",
    "    )\n",
    "\n",
    "    # Affichage du graphique\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rendement Moyen  Écart Type  Taux sans Risque  Sharpe Ratio  PNL Finale\n",
      "0         0.016567    0.156385              0.02     -0.021955    0.496999\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Création du tableau synthétique\n",
    "data = {\n",
    "    'Rendement Moyen': [Rp],\n",
    "    'Écart Type': [sigma_p],\n",
    "    'Taux sans Risque': [Rf],\n",
    "    'Sharpe Ratio': [SR],\n",
    "    'PNL Finale': [PNL[-1]]\n",
    "}\n",
    "\n",
    "table = pd.DataFrame(data)\n",
    "\n",
    "# Affichage du tableau\n",
    "print(table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
