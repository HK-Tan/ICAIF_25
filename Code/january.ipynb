{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ÉTAPE 0** : préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no NaN values in the dataframe\n"
     ]
    }
   ],
   "source": [
    "import process \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Nail path : '/Users/khelifanail/Documents/GitHub/Portfolio_clustering_project/Data/DATA_Statapp.csv'\n",
    "# Jerome path : 'C:\\Users\\33640\\OneDrive\\Documents\\GitHub\\Portfolio_clustering_project\\Data\\DATA_Statapp.csv'\n",
    "# Mohamed path : '/Users/khelifanail/Documents/GitHub/Portfolio_clustering_project/Data/DATA_Statapp.csv'\n",
    "df = pd.read_csv('/Users/khelifanail/Documents/GitHub/Portfolio_clustering_project/Data/DATA_Statapp.csv')\n",
    "\n",
    "# Apply conversion function to 'open' and 'close' columns\n",
    "df['open'] = df['open'].apply(process.safe_literal_eval)\n",
    "df['close'] = df['close'].apply(process.safe_literal_eval)\n",
    "\n",
    "# Calculate returns for each line\n",
    "df['return'] = df.apply(lambda row: [(close - open) / open for open, close in zip(row['open'], row['close'])], axis=1)\n",
    "\n",
    "new_df = df[['ticker', 'return']] # create a new data frame with the column ticker and return \n",
    "\n",
    "# Créons le DataFrame à partir des listes dans 'return'\n",
    "# On suppose ici que 'new_df' est déjà défini et contient la colonne 'return'\n",
    "\n",
    "# Convertir chaque liste dans la colonne 'return' en plusieurs colonnes dans le nouveau DataFrame\n",
    "returns_df = pd.DataFrame(new_df['return'].tolist())\n",
    "\n",
    "# Ajouter la colonne 'ticker' du 'new_df' au début de 'returns_df'\n",
    "returns_df.insert(0, 'ticker', new_df['ticker'])\n",
    "\n",
    "# Renommer les colonnes pour refléter qu'elles sont des rendements\n",
    "returns_df.columns = ['ticker'] + [f'return_{i}' for i in range(len(returns_df.columns) - 1)]\n",
    "\n",
    "df_cleaned = process.remove_rows_with_nan(returns_df)\n",
    "df_cleaned.reset_index(drop=True, inplace=True)\n",
    "\n",
    "process.check_nan_inf(df_cleaned)\n",
    "\n",
    "df_cleaned.set_index('ticker', inplace=True) ## ces deux lignes sont fondamentales, ne pas les retirer !!\n",
    "df.set_index('ticker', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import process \n",
    "lookback_window = [5000, 5250]\n",
    "corr_matrix = process.correlation_matrix(lookback_window=lookback_window, df_cleaned=df_cleaned)\n",
    "cluster_composition_and_centroid = process.cluster_composition_and_centroid(df_cleaned=df_cleaned, correlation_matrix=corr_matrix, number_of_clusters=20, lookback_window=lookback_window)\n",
    "constituent_weights = process.constituent_weights(\n",
    "    df_cleaned=df_cleaned, \n",
    "    cluster_composition=cluster_composition_and_centroid, \n",
    "    sigma=10, \n",
    "    lookback_window=lookback_window\n",
    ")\n",
    "cluster_return = process.cluster_return(constituent_weights=constituent_weights, df_cleaned=df_cleaned, df=df, lookback_window=lookback_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_matrix = cluster_return.transpose().cov()\n",
    "cluster_return_target = process.cluster_return(constituent_weights=constituent_weights, df_cleaned=df_cleaned, df=df, lookback_window=[lookback_window[1], lookback_window[1]+1])\n",
    "expected_returns = process.noised_array(y=cluster_return_target, eta=0.01).iloc[:, 0].values.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.538109308693756"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_returns.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('cluster 1', 0.0),\n",
       "             ('cluster 2', 0.0),\n",
       "             ('cluster 3', 0.20814),\n",
       "             ('cluster 4', 0.16552),\n",
       "             ('cluster 5', 0.0),\n",
       "             ('cluster 6', 0.0),\n",
       "             ('cluster 7', 0.05284),\n",
       "             ('cluster 8', 0.0),\n",
       "             ('cluster 9', 0.23842),\n",
       "             ('cluster 10', 0.0),\n",
       "             ('cluster 11', 0.07347),\n",
       "             ('cluster 12', 0.0),\n",
       "             ('cluster 13', 0.0),\n",
       "             ('cluster 14', 0.0),\n",
       "             ('cluster 15', 0.0),\n",
       "             ('cluster 16', 0.10912),\n",
       "             ('cluster 17', 0.0),\n",
       "             ('cluster 18', 0.0),\n",
       "             ('cluster 19', 0.1525)])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "\n",
    "ef = EfficientFrontier(expected_returns=expected_returns, cov_matrix=cov_matrix, weight_bounds=(0, 1))\n",
    "ef. efficient_return(target_return=expected_returns.mean())\n",
    "ef.clean_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markowitz_weights = process.markowitz_weights(cluster_return_res=cluster_return, constituent_weights=constituent_weights, df_cleaned=df_cleaned, df=df, lookback_window=lookback_window, eta=0.01)\n",
    "final_weights = process.final_weights(markowitz_weights=markowitz_weights, constituent_weights=constituent_weights)\n",
    "consolidated_W = process.consolidated_W(number_of_repetitions=2, lookback_window=lookback_window, df_cleaned=df_cleaned, number_of_clusters=20, sigma=10e-2, df=df, eta=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_return = process.portfolio_returns(evaluation_window=10, df_cleaned=df_cleaned, lookback_window=lookback_window, consolidated_W=consolidated_W, df=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Quadratic form matrices must be symmetric/Hermitian.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/khelifanail/Documents/GitHub/Portfolio_clustering_project/Code/january.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/khelifanail/Documents/GitHub/Portfolio_clustering_project/Code/january.ipynb#X20sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m overall_return \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/khelifanail/Documents/GitHub/Portfolio_clustering_project/Code/january.ipynb#X20sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m portfolio_value\u001b[39m=\u001b[39m[\u001b[39m1\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/khelifanail/Documents/GitHub/Portfolio_clustering_project/Code/january.ipynb#X20sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m consolidated_W \u001b[39m=\u001b[39m process\u001b[39m.\u001b[39;49mconsolidated_W(number_of_repetitions\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, lookback_window\u001b[39m=\u001b[39;49mlookback_window, df_cleaned\u001b[39m=\u001b[39;49mdf_cleaned, number_of_clusters\u001b[39m=\u001b[39;49mnumber_of_clusters, sigma\u001b[39m=\u001b[39;49msigma, df\u001b[39m=\u001b[39;49mdf, eta\u001b[39m=\u001b[39;49meta)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/khelifanail/Documents/GitHub/Portfolio_clustering_project/Code/january.ipynb#X20sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m portfolio_return \u001b[39m=\u001b[39m process\u001b[39m.\u001b[39mportfolio_returns(evaluation_window\u001b[39m=\u001b[39mevaluation_window, df_cleaned\u001b[39m=\u001b[39mdf_cleaned, lookback_window\u001b[39m=\u001b[39mlookback_window, consolidated_W\u001b[39m=\u001b[39mconsolidated_W, df\u001b[39m=\u001b[39mdf)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/khelifanail/Documents/GitHub/Portfolio_clustering_project/Code/january.ipynb#X20sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m overall_return \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([overall_return, portfolio_return])\n",
      "File \u001b[0;32m~/Documents/GitHub/Portfolio_clustering_project/Code/process.py:600\u001b[0m, in \u001b[0;36mconsolidated_W\u001b[0;34m(number_of_repetitions, lookback_window, df_cleaned, number_of_clusters, sigma, df, eta, clustering_method)\u001b[0m\n\u001b[1;32m    597\u001b[0m history \u001b[39m=\u001b[39m []\n\u001b[1;32m    599\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(number_of_repetitions):\n\u001b[0;32m--> 600\u001b[0m     W \u001b[39m=\u001b[39m training_phase(lookback_window\u001b[39m=\u001b[39;49mlookback_window, df_cleaned\u001b[39m=\u001b[39;49mdf_cleaned, number_of_clusters\u001b[39m=\u001b[39;49mnumber_of_clusters, sigma\u001b[39m=\u001b[39;49msigma, df\u001b[39m=\u001b[39;49mdf, eta\u001b[39m=\u001b[39;49meta, clustering_method\u001b[39m=\u001b[39;49mclustering_method)\n\u001b[1;32m    601\u001b[0m     history\u001b[39m.\u001b[39mappend(W)\n\u001b[1;32m    603\u001b[0m consolidated_W \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(index\u001b[39m=\u001b[39mdf_cleaned\u001b[39m.\u001b[39mindex, columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mweight\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/Documents/GitHub/Portfolio_clustering_project/Code/process.py:547\u001b[0m, in \u001b[0;36mtraining_phase\u001b[0;34m(lookback_window, df_cleaned, number_of_clusters, sigma, df, eta, clustering_method)\u001b[0m\n\u001b[1;32m    544\u001b[0m cluster_return_result \u001b[39m=\u001b[39m cluster_return(constituent_weights\u001b[39m=\u001b[39mconstituent_weights_res, df_cleaned\u001b[39m=\u001b[39mdf_cleaned, df\u001b[39m=\u001b[39mdf, lookback_window\u001b[39m=\u001b[39mlookback_window) \n\u001b[1;32m    546\u001b[0m \u001b[39m## ÉTAPE 5 : on obtient les poids de markowitz de chaque cluster\u001b[39;00m\n\u001b[0;32m--> 547\u001b[0m markowitz_weights_res \u001b[39m=\u001b[39m markowitz_weights(cluster_return_res\u001b[39m=\u001b[39;49mcluster_return_result, constituent_weights\u001b[39m=\u001b[39;49mconstituent_weights_res, df_cleaned\u001b[39m=\u001b[39;49mdf_cleaned, df\u001b[39m=\u001b[39;49mdf, lookback_window\u001b[39m=\u001b[39;49mlookback_window, eta\u001b[39m=\u001b[39;49meta)\n\u001b[1;32m    549\u001b[0m \u001b[39m## ÉTAPE 6 : on remonte aux poids de chaque actif dans l'ensemble\u001b[39;00m\n\u001b[1;32m    550\u001b[0m W \u001b[39m=\u001b[39m final_weights(markowitz_weights\u001b[39m=\u001b[39mmarkowitz_weights_res, constituent_weights\u001b[39m=\u001b[39mconstituent_weights_res)\n",
      "File \u001b[0;32m~/Documents/GitHub/Portfolio_clustering_project/Code/process.py:450\u001b[0m, in \u001b[0;36mmarkowitz_weights\u001b[0;34m(cluster_return_res, constituent_weights, df_cleaned, df, lookback_window, eta)\u001b[0m\n\u001b[1;32m    447\u001b[0m expected_returns \u001b[39m=\u001b[39m noised_array(y\u001b[39m=\u001b[39mcluster_target_return, eta\u001b[39m=\u001b[39meta)\u001b[39m.\u001b[39miloc[:, \u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39msqueeze()\n\u001b[1;32m    449\u001b[0m ef \u001b[39m=\u001b[39m EfficientFrontier(expected_returns\u001b[39m=\u001b[39mexpected_returns, cov_matrix\u001b[39m=\u001b[39mcov_matrix)\n\u001b[0;32m--> 450\u001b[0m ef\u001b[39m.\u001b[39;49mmax_sharpe()\n\u001b[1;32m    452\u001b[0m markowitz_weights \u001b[39m=\u001b[39m ef\u001b[39m.\u001b[39mclean_weights()\n\u001b[1;32m    454\u001b[0m \u001b[39mreturn\u001b[39;00m markowitz_weights\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pypfopt/efficient_frontier/efficient_frontier.py:253\u001b[0m, in \u001b[0;36mEfficientFrontier.max_sharpe\u001b[0;34m(self, risk_free_rate)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_risk_free_rate \u001b[39m=\u001b[39m risk_free_rate\n\u001b[1;32m    251\u001b[0m \u001b[39m# max_sharpe requires us to make a variable transformation.\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[39m# Here we treat w as the transformed variable.\u001b[39;00m\n\u001b[0;32m--> 253\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_objective \u001b[39m=\u001b[39m cp\u001b[39m.\u001b[39;49mquad_form(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_w, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcov_matrix)\n\u001b[1;32m    254\u001b[0m k \u001b[39m=\u001b[39m cp\u001b[39m.\u001b[39mVariable()\n\u001b[1;32m    256\u001b[0m \u001b[39m# Note: objectives are not scaled by k. Hence there are subtle differences\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[39m# between how these objectives work for max_sharpe vs min_volatility\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/cvxpy/atoms/quad_form.py:252\u001b[0m, in \u001b[0;36mquad_form\u001b[0;34m(x, P, assume_PSD)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[39mif\u001b[39;00m assume_PSD:\n\u001b[1;32m    251\u001b[0m         P \u001b[39m=\u001b[39m psd_wrap(P)\n\u001b[0;32m--> 252\u001b[0m     \u001b[39mreturn\u001b[39;00m QuadForm(x, P)\n\u001b[1;32m    253\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    254\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\n\u001b[1;32m    255\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAt least one argument to quad_form must be non-variable.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    256\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/cvxpy/atoms/quad_form.py:42\u001b[0m, in \u001b[0;36mQuadForm.__init__\u001b[0;34m(self, x, P)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, x, P) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     41\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Atom representing :math:`x^T P x`.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m     \u001b[39msuper\u001b[39;49m(QuadForm, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(x, P)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/cvxpy/atoms/atom.py:50\u001b[0m, in \u001b[0;36mAtom.__init__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39m# Convert raw values to Constants.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs \u001b[39m=\u001b[39m [Atom\u001b[39m.\u001b[39mcast_to_const(arg) \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m args]\n\u001b[0;32m---> 50\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalidate_arguments()\n\u001b[1;32m     51\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shape \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape_from_args()\n\u001b[1;32m     52\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shape) \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/cvxpy/atoms/quad_form.py:58\u001b[0m, in \u001b[0;36mQuadForm.validate_arguments\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInvalid dimensions for arguments.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     57\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mis_hermitian():\n\u001b[0;32m---> 58\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mQuadratic form matrices must be symmetric/Hermitian.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Quadratic form matrices must be symmetric/Hermitian."
     ]
    }
   ],
   "source": [
    "import process\n",
    "import warnings \n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "lookback_window = [5000, 5250]\n",
    "number_of_clusters = 20\n",
    "sigma = 10e-3\n",
    "clustering_method = 'SPONGE' \n",
    "number_of_repetition = 20\n",
    "evaluation_window = 10\n",
    "eta=0.01\n",
    "\n",
    "PnL = []\n",
    "overall_return = pd.DataFrame()\n",
    "portfolio_value=[1]\n",
    "\n",
    "consolidated_W = process.consolidated_W(number_of_repetitions=10, lookback_window=lookback_window, df_cleaned=df_cleaned, number_of_clusters=number_of_clusters, sigma=sigma, df=df, eta=eta)\n",
    "\n",
    "portfolio_return = process.portfolio_returns(evaluation_window=evaluation_window, df_cleaned=df_cleaned, lookback_window=lookback_window, consolidated_W=consolidated_W, df=df)\n",
    "\n",
    "overall_return = pd.concat([overall_return, portfolio_return])\n",
    "\n",
    "PnL = np.concatenate((PnL, np.reshape(np.cumprod(1 + portfolio_return)*portfolio_value[-1] - portfolio_value[-1], (evaluation_window,))))## car on réinvestit immédiatement après \n",
    "portfolio_value.append(portfolio_value[-1]+PnL[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
