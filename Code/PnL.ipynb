{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'Main_modules'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mMain_modules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mPnL_utilities\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'Main_modules'"
          ]
        }
      ],
      "source": [
        "from Main_modules.PnL_utilities import *\n",
        "import torch\n",
        "import pandas as pd\n",
        "import tdqm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- REFACTORED Main processing function for a single window ---\n",
        "def single_window_iteration_processor_refactored(\n",
        "    lookback_asset_returns_item,\n",
        "    eval_asset_returns_item_padded,\n",
        "    current_eval_len_for_window,\n",
        "    window_idx_batch,\n",
        "    initial_n_clusters_config_static,\n",
        "    cluster_method_static,\n",
        "    var_order_static,\n",
        "    sigma_for_weights_static,\n",
        "    max_eval_len_static,\n",
        "    run_naive_var_comparison_static,\n",
        "    num_assets_overall_static,\n",
        "    device_static\n",
        "):\n",
        "    actual_eval_asset_returns_item = eval_asset_returns_item_padded\n",
        "\n",
        "    cluster_defs, cluster_names_ord, actual_n_clust_formed, _ = _define_clusters_and_centroids_functional(\n",
        "        lookback_asset_returns_item, initial_n_clusters_config_static, cluster_method_static, device_static\n",
        "    )\n",
        "\n",
        "    # Removed 'if cluster_names_ord:'\n",
        "    lookback_cluster_returns = _calculate_weighted_cluster_returns_functional(\n",
        "        data_slice_for_returns_calc=lookback_asset_returns_item,\n",
        "        data_slice_for_centroid_weights_calc=lookback_asset_returns_item,\n",
        "        cluster_definitions=cluster_defs,\n",
        "        cluster_names_ordered=cluster_names_ord,\n",
        "        sigma_for_weights=sigma_for_weights_static\n",
        "    )\n",
        "\n",
        "    # print(lookback_cluster_returns)\n",
        "\n",
        "    # Removed 'if lookback_cluster_returns.numel() > 0 and lookback_cluster_returns.shape[1] > 0:'\n",
        "    forecasted_cluster_returns_raw = _fit_var_and_forecast_functional(\n",
        "        lookback_cluster_returns, actual_n_clust_formed, var_order_static,\n",
        "        current_eval_len_for_window, device_static\n",
        "    )\n",
        "\n",
        "\n",
        "    # Removed 'if current_eval_len_for_window > 0:'\n",
        "    true_eval_cluster_returns_raw = _calculate_weighted_cluster_returns_functional(\n",
        "        data_slice_for_returns_calc=actual_eval_asset_returns_item,\n",
        "        data_slice_for_centroid_weights_calc=lookback_asset_returns_item,\n",
        "        cluster_definitions=cluster_defs,\n",
        "        cluster_names_ordered=cluster_names_ord,\n",
        "        sigma_for_weights=sigma_for_weights_static\n",
        "    )\n",
        "\n",
        "    pnl_c_tensor = calculate_pnl_torch(forecasted_cluster_returns_raw, true_eval_cluster_returns_raw)\n",
        "    # Removed 'if pnl_c_tensor.numel() > 0:'\n",
        "    pnl_c_val = pnl_c_tensor.mean().to(torch.float32)\n",
        "    # Removed 'if torch.isnan(pnl_c_val):'\n",
        "\n",
        "    pnl_n_val = torch.tensor(0.0, dtype=torch.float32, device=device_static)\n",
        "    forecasted_naive_returns_raw = torch.tensor(0.0, dtype=torch.float32, device=device_static)\n",
        "    true_eval_naive_returns_raw = torch.tensor(0.0, dtype=torch.float32, device=device_static)\n",
        "\n",
        "    if run_naive_var_comparison_static:\n",
        "        # Removed 'if lookback_asset_returns_item.numel() > 0 and lookback_asset_returns_item.shape[1] > 0 :'\n",
        "        forecasted_naive_returns_raw = _fit_var_and_forecast_functional(\n",
        "            lookback_asset_returns_item, num_assets_overall_static, var_order_static,\n",
        "            current_eval_len_for_window, device_static\n",
        "        )\n",
        "\n",
        "        # Removed 'if current_eval_len_for_window > 0:'\n",
        "        true_eval_naive_returns_raw = actual_eval_asset_returns_item\n",
        "\n",
        "        pnl_n_tensor = calculate_pnl_torch(forecasted_naive_returns_raw, forecasted_naive_returns_raw)\n",
        "        # Removed 'if pnl_n_tensor.numel() > 0:'\n",
        "        pnl_n_val = pnl_n_tensor.mean().to(torch.float32)\n",
        "        # Removed 'if torch.isnan(pnl_n_val):'\n",
        "\n",
        "    return (pnl_c_val, forecasted_cluster_returns_raw, true_eval_cluster_returns_raw,\n",
        "            pnl_n_val, forecasted_naive_returns_raw, true_eval_naive_returns_raw,\n",
        "            window_idx_batch\n",
        "           )\n",
        "\n",
        "# --- REFACTORED Main sliding window function ---\n",
        "def run_sliding_window_var_evaluation_vmap(\n",
        "    asset_returns_tensor, initial_lookback_len, eval_len, n_clusters_config,\n",
        "    cluster_method, var_order, sigma_intra_cluster, num_windows,\n",
        "    device=None, store_sample_forecasts=True, run_naive_var_comparison=True\n",
        "):\n",
        "    # Removed 'if device is None:' device will be asset_returns_tensor.device if not passed\n",
        "    effective_device = device if device is not None else asset_returns_tensor.device\n",
        "\n",
        "    num_assets_overall = asset_returns_tensor.shape[1]\n",
        "    tensor_total_len = asset_returns_tensor.shape[0]\n",
        "\n",
        "    base_lookback_start_indices = torch.arange(num_windows, device=effective_device) * eval_len\n",
        "    base_lookback_end_indices = base_lookback_start_indices + initial_lookback_len\n",
        "\n",
        "    valid_mask_initial = (base_lookback_end_indices <= tensor_total_len) & \\\n",
        "                         (base_lookback_end_indices < tensor_total_len)\n",
        "\n",
        "    filtered_lb_start_indices = base_lookback_start_indices[valid_mask_initial]\n",
        "    filtered_lb_end_indices = base_lookback_end_indices[valid_mask_initial]\n",
        "    original_window_indices_filtered = torch.arange(num_windows, device=effective_device)[valid_mask_initial]\n",
        "\n",
        "    # Removed 'if len(filtered_lb_start_indices) == 0:' and early return\n",
        "\n",
        "    num_potentially_valid_windows = len(filtered_lb_start_indices)\n",
        "    current_eval_lens_for_filtered = torch.full((num_potentially_valid_windows,), eval_len, dtype=torch.long, device=effective_device)\n",
        "    for i in range(num_potentially_valid_windows): # This loop might be empty if num_potentially_valid_windows is 0\n",
        "        max_possible_eval_len = tensor_total_len - filtered_lb_end_indices[i]\n",
        "        current_eval_lens_for_filtered[i] = min(eval_len, max_possible_eval_len)\n",
        "\n",
        "    valid_mask_eval_len = current_eval_lens_for_filtered > 0\n",
        "\n",
        "    final_lookback_start_indices = filtered_lb_start_indices[valid_mask_eval_len]\n",
        "    final_lookback_end_indices = filtered_lb_end_indices[valid_mask_eval_len]\n",
        "    final_current_eval_lens = current_eval_lens_for_filtered[valid_mask_eval_len]\n",
        "    final_original_window_indices_batch = original_window_indices_filtered[valid_mask_eval_len]\n",
        "\n",
        "    # Removed 'if len(final_lookback_start_indices) == 0:' and early return\n",
        "\n",
        "    actual_num_windows_to_process = len(final_lookback_start_indices)\n",
        "\n",
        "    batched_lookback_slices = []\n",
        "    batched_eval_slices_padded = []\n",
        "\n",
        "    # for _ in repeat_for_robustness:\n",
        "    #   for p in lag_orders_to_test:\n",
        "    #       for k in num_clusters_to_test:\n",
        "    for s in range(actual_num_windows_to_process): # This loop might be empty\n",
        "        start = final_lookback_start_indices[s]\n",
        "        end = final_lookback_end_indices[s]\n",
        "\n",
        "        lb_slice = asset_returns_tensor[start:end, :]\n",
        "        batched_lookback_slices.append(lb_slice)\n",
        "\n",
        "        eval_s = end\n",
        "        current_L = final_current_eval_lens[s].item()\n",
        "        eval_e = eval_s + current_L\n",
        "        ev_slice_actual = asset_returns_tensor[eval_s:eval_e, :]\n",
        "\n",
        "        # # Padding logic kept for vmap compatibility\n",
        "        # if current_L < eval_len:\n",
        "        #     padding = torch.zeros((eval_len - current_L, num_assets_overall),\n",
        "        #                           dtype=asset_returns_tensor.dtype, device=effective_device)\n",
        "        #     ev_slice_padded = torch.cat([ev_slice_actual, padding], dim=0)\n",
        "        # elif current_L == eval_len:\n",
        "        #     ev_slice_padded = ev_slice_actual\n",
        "        # else:\n",
        "        #     ev_slice_padded = ev_slice_actual[:eval_len,:]\n",
        "\n",
        "        batched_eval_slices_padded.append(ev_slice_actual)\n",
        "\n",
        "    # These stacks will error if their respective lists are empty (e.g., actual_num_windows_to_process is 0)\n",
        "    final_batched_lookback_data = torch.stack(batched_lookback_slices)\n",
        "    final_batched_eval_data_padded = torch.stack(batched_eval_slices_padded)\n",
        "\n",
        "\n",
        "    vmapped_processor = func.vmap(\n",
        "        single_window_iteration_processor_refactored,\n",
        "        in_dims=(0, 0, None, 0,\n",
        "                   None, None, None, None, None, None, None, None),\n",
        "        out_dims=0, randomness='different'\n",
        "    )\n",
        "\n",
        "    all_pnl_c_vals, all_forecast_c, all_actual_c, \\\n",
        "    all_pnl_n_vals, all_forecast_n, all_actual_n, \\\n",
        "    processed_window_indices = vmapped_processor(\n",
        "        final_batched_lookback_data,\n",
        "        final_batched_eval_data_padded,\n",
        "        eval_len,\n",
        "        final_original_window_indices_batch,\n",
        "        n_clusters_config,\n",
        "        cluster_method,\n",
        "        var_order,\n",
        "        sigma_intra_cluster,\n",
        "        eval_len,\n",
        "        run_naive_var_comparison,\n",
        "        num_assets_overall,\n",
        "        effective_device\n",
        "    )\n",
        "\n",
        "    all_window_pnl_cluster_dicts = []\n",
        "    all_window_pnl_naive_dicts = []\n",
        "\n",
        "    for i in range(actual_num_windows_to_process): # This loop might be empty\n",
        "        win_id = processed_window_indices[i].item()\n",
        "\n",
        "        # Removed filter 'if all_pnl_c_vals[i].item() != 0.0 or all_forecast_c[i].abs().sum() > 1e-9:'\n",
        "        all_window_pnl_cluster_dicts.append({\n",
        "             'Window_ID': win_id, 'Avg_Window_PNL': all_pnl_c_vals[i].item(),\n",
        "             'VAR_Order': var_order, 'Method': 'Clustered VAR'\n",
        "         })\n",
        "\n",
        "        if run_naive_var_comparison:\n",
        "            # Removed filter for naive pnl/forecast values\n",
        "            all_window_pnl_naive_dicts.append({\n",
        "                'Window_ID': win_id, 'Avg_Window_PNL': all_pnl_n_vals[i].item(),\n",
        "                'VAR_Order': var_order, 'Method': 'Naive VAR'\n",
        "            })\n",
        "\n",
        "    sample_forecast_c, sample_actual_c, sample_win_idx = None, None, -1\n",
        "    # Removed 'and actual_num_windows_to_process > 0' from condition\n",
        "    if store_sample_forecasts:\n",
        "        sample_idx_in_batch = 0 # Will error if actual_num_windows_to_process is 0\n",
        "        actual_eval_len_for_sample = final_current_eval_lens[sample_idx_in_batch].item()\n",
        "\n",
        "        sample_forecast_c = all_forecast_c[sample_idx_in_batch, :actual_eval_len_for_sample, :].clone()\n",
        "        sample_actual_c = all_actual_c[sample_idx_in_batch, :actual_eval_len_for_sample, :].clone()\n",
        "        sample_win_idx = processed_window_indices[sample_idx_in_batch].item()\n",
        "\n",
        "    return {\n",
        "        'cluster_avg_pnl_list': all_window_pnl_cluster_dicts,\n",
        "        'naive_avg_pnl_list': all_window_pnl_naive_dicts,\n",
        "        'sample_forecast_cluster': sample_forecast_c,\n",
        "        'sample_actual_cluster': sample_actual_c,\n",
        "        'sample_window_idx_cluster': sample_win_idx,\n",
        "        'var_order_for_sample': var_order\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"## 1. Load and Clean Data\"\"\"\n",
        "\n",
        "# file_path = r'OPCL_20000103_20201231.csv' # Path to your data file\n",
        "file_path = r'N:\\GitHub\\ICAIF_25\\Data\\OPCL_20000103_20201231.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "device = 'cuda:0'\n",
        "\n",
        "# Removed 'if not df.empty:' checks. Code will error if df is empty and operations are called.\n",
        "df.set_index('ticker', inplace=True)\n",
        "df.columns = pd.to_datetime(df.columns.str.lstrip('X'), format='%Y%m%d').strftime('%Y-%m-%d')\n",
        "df_cleaned = df.dropna().transpose()\n",
        "df_cleaned.index = pd.to_datetime(df_cleaned.index)\n",
        "print(\"Data loaded and cleaned. Sample (first 5 rows/cols):\")\n",
        "# This print will error if df_cleaned is too small or empty.\n",
        "print(df_cleaned.iloc[0:5,0:5])\n",
        "\n",
        "print(f\"Shape of the cleaned data: {df_cleaned.shape}\")\n",
        "\n",
        "numpy_array = df_cleaned.astype(float).values\n",
        "historical_data_tensor = torch.from_numpy(numpy_array).float()\n",
        "historical_data_tensor = historical_data_tensor.to(device)\n",
        "# historical_data_tensor = torch.log1p(historical_data_tensor)\n",
        "\"\"\"## 2. VAR Lag Grid Search and Evaluation\"\"\"\n",
        "\n",
        "##################################################################### PARAMETERS #####################################################################\n",
        "initial_lookback_len = 252\n",
        "evaluation_len = 5\n",
        "num_clusters_config = 20\n",
        "cluster_method_config = 'spectral_clustering'\n",
        "sigma_config = 0.5\n",
        "num_windows_config = 25\n",
        "var_orders_to_test_config = range(5,11,2)\n",
        "####################################################################################################################################################\n",
        "\n",
        "all_lags_combined_pnl_data = []\n",
        "final_sample_details = {}\n",
        "\n",
        "# Removed dummy data definition block for testing as it's a form of edge case / setup handling.\n",
        "# The script now assumes 'historical_data_tensor' and 'device' are correctly defined.\n",
        "# if 'historical_data_tensor' not in globals() or 'device' not in globals():\n",
        "#    ...\n",
        "\n",
        "# Removed 'if historical_data_tensor.numel() > 0:'\n",
        "for var_order_val in tqdm(var_orders_to_test_config, desc=\"VAR Order Grid Search\"):\n",
        "    results = run_sliding_window_var_evaluation_vmap(\n",
        "        asset_returns_tensor=historical_data_tensor, # Will error if not defined or empty and used inappropriately by functions\n",
        "        initial_lookback_len=initial_lookback_len,\n",
        "        eval_len=evaluation_len,\n",
        "        n_clusters_config=num_clusters_config,\n",
        "        cluster_method=cluster_method_config,\n",
        "        var_order=var_order_val,\n",
        "        sigma_intra_cluster=sigma_config,\n",
        "        num_windows=num_windows_config,\n",
        "        device=device,\n",
        "        store_sample_forecasts=(var_order_val == var_orders_to_test_config[-1]),\n",
        "        run_naive_var_comparison=False\n",
        "    )\n",
        "    all_lags_combined_pnl_data.extend(results['cluster_avg_pnl_list'])\n",
        "    all_lags_combined_pnl_data.extend(results['naive_avg_pnl_list'])\n",
        "\n",
        "    # Removed 'and results.get('sample_forecast_cluster') is not None'\n",
        "    if (var_order_val == var_orders_to_test_config[-1]):\n",
        "        final_sample_details = results # Will store even if sample is None\n",
        "\n",
        "print(\"\\n--- Grid Search Completed ---\")\n",
        "# Removed 'if all_lags_combined_pnl_data:'\n",
        "agg_data = {}\n",
        "methods_seen = set()\n",
        "for record in all_lags_combined_pnl_data: # Will error if all_lags_combined_pnl_data is empty but accessed.\n",
        "    methods_seen.add(record['Method'])\n",
        "    key = (record['VAR_Order'], record['Method'])\n",
        "    agg_data.setdefault(key, []).append(record['Avg_Window_PNL'])\n",
        "\n",
        "sorted_methods = sorted(list(methods_seen))\n",
        "# Removed 'if not sorted_methods:'\n",
        "header = f\"{'VAR_Order':<10} | \" + \" | \".join([f\"{m:<15}\" for m in sorted_methods])\n",
        "print(\"\\nAverage Window PNL per Lag Order and Method:\")\n",
        "print(header)\n",
        "print(\"-\" * len(header))\n",
        "\n",
        "for var_order in sorted(list(set(r['VAR_Order'] for r in all_lags_combined_pnl_data))):\n",
        "    row_str = f\"{var_order:<10} | \"\n",
        "    for method in sorted_methods:\n",
        "        pnl_list = agg_data.get((var_order, method), []) # Keep .get for safety or it could KeyError\n",
        "        # Removed 'if pnl_list:' for calculating avg_pnl. Division by zero if len is 0.\n",
        "        avg_pnl = sum(pnl_list) / len(pnl_list) if pnl_list else float('nan') # Retained minimal check to avoid div by zero for print\n",
        "        row_str += f\"{avg_pnl:<15.6f} | \"\n",
        "    print(row_str.strip().rsplit('|', 1)[0].strip())\n",
        "\n",
        "\n",
        "# 3. Visualization\n",
        "# Removed 'if all_lags_combined_pnl_data:'\n",
        "# Removed 'try-except' block for plotting\n",
        "# Filter for valid numeric PNLs for plotting to prevent seaborn/matplotlib errors. This is a practical necessity for plotting.\n",
        "plot_data_list = [d for d in all_lags_combined_pnl_data if isinstance(d.get('Avg_Window_PNL'), (int, float)) and not np.isnan(d.get('Avg_Window_PNL'))]\n",
        "\n",
        "# Removed 'if plot_data_list:'\n",
        "plot_df_data = {\n",
        "    'VAR_Order': [d['VAR_Order'] for d in plot_data_list],\n",
        "    'Avg_Window_PNL': [d['Avg_Window_PNL'] for d in plot_data_list],\n",
        "    'Method': [d['Method'] for d in plot_data_list]\n",
        "}\n",
        "plt.figure(figsize=(14, 8))\n",
        "sns.boxplot(x='VAR_Order', y='Avg_Window_PNL', hue='Method', data=plot_df_data) # Will error if plot_df_data is empty/malformed\n",
        "plt.title('Distribution of Avg Window PNL by VAR Lag & Method (PyTorch with vmap)')\n",
        "plt.xlabel('VAR Lag Order'); plt.ylabel('Avg Window PNL')\n",
        "plt.legend(title='Forecast Method'); plt.grid(True, axis='y', alpha=0.7)\n",
        "plt.tight_layout(); plt.show()\n",
        "\n",
        "\n",
        "# Removed 'if final_sample_details and final_sample_details.get('sample_forecast_cluster') is not None:'\n",
        "# Direct access, will error if keys don't exist or values are None and methods are called.\n",
        "fc = final_sample_details['sample_forecast_cluster'].cpu().numpy()\n",
        "ac = final_sample_details['sample_actual_cluster'].cpu().numpy()\n",
        "win_idx = final_sample_details['sample_window_idx_cluster']\n",
        "var_ord_sample = final_sample_details['var_order_for_sample']\n",
        "\n",
        "print(f\"\\n--- Plotting Sample: Window {win_idx + 1 if win_idx != -1 else 'N/A'}, Clustered VAR Lag {var_ord_sample} ---\")\n",
        "num_series_to_plot = min(3, fc.shape[1]) # fc.shape[1] will error if fc is None\n",
        "# Removed 'if num_series_to_plot == 0:'\n",
        "\n",
        "for i in range(num_series_to_plot):\n",
        "    plt.figure(figsize=(14, 7))\n",
        "    # Removed data/length validation before plotting. Plotting functions might error.\n",
        "    sns.lineplot(x=range(len(ac[:, i])), y=ac[:, i], label=f'Actual Cluster {i+1}', marker='o')\n",
        "    sns.lineplot(x=range(len(fc[:, i])), y=fc[:, i], label=f'Forecast Cluster {i+1}', marker='x', linestyle='--')\n",
        "    plt.title(f'Prediction vs Actual for Cluster {i+1} (Win {win_idx+1 if win_idx != -1 else \"N/A\"}, VAR {var_ord_sample}, PyTorch with vmap)')\n",
        "    plt.xlabel('Forecast Step'); plt.ylabel('Cluster Return')\n",
        "    plt.legend(); plt.grid(True); plt.tight_layout(); plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
