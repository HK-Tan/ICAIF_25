{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from Main_modules.PnL_utilities import _calculate_weighted_cluster_returns_functional, _fit_var_and_forecast_functional, calculate_pnl_torch, _define_clusters_and_centroids_functional\n",
        "import torch\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch.func as func\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- REFACTORED Main processing function for a single window ---\n",
        "def single_window_iteration_processor_refactored(\n",
        "    lookback_asset_returns_item,\n",
        "    eval_asset_returns_item_padded,\n",
        "    current_eval_len_for_window,\n",
        "    window_idx_batch,\n",
        "    initial_n_clusters_config_static,\n",
        "    cluster_method_static,\n",
        "    var_order_static,\n",
        "    sigma_for_weights_static,\n",
        "    max_eval_len_static,\n",
        "    run_naive_var_comparison_static,\n",
        "    num_assets_overall_static,\n",
        "    device_static\n",
        "):\n",
        "    actual_eval_asset_returns_item = eval_asset_returns_item_padded\n",
        "\n",
        "    cluster_defs, cluster_names_ord, actual_n_clust_formed, _ = _define_clusters_and_centroids_functional(\n",
        "        lookback_asset_returns_item, initial_n_clusters_config_static, cluster_method_static, device_static\n",
        "    )\n",
        "\n",
        "    # Removed 'if cluster_names_ord:'\n",
        "    lookback_cluster_returns = _calculate_weighted_cluster_returns_functional(\n",
        "        data_slice_for_returns_calc=lookback_asset_returns_item,\n",
        "        data_slice_for_centroid_weights_calc=lookback_asset_returns_item,\n",
        "        cluster_definitions=cluster_defs,\n",
        "        cluster_names_ordered=cluster_names_ord,\n",
        "        sigma_for_weights=sigma_for_weights_static\n",
        "    )\n",
        "\n",
        "    # print(lookback_cluster_returns)\n",
        "\n",
        "    # Removed 'if lookback_cluster_returns.numel() > 0 and lookback_cluster_returns.shape[1] > 0:'\n",
        "    forecasted_cluster_returns_raw = _fit_var_and_forecast_functional(\n",
        "        lookback_cluster_returns, actual_n_clust_formed, var_order_static,\n",
        "        current_eval_len_for_window, device_static\n",
        "    )\n",
        "\n",
        "\n",
        "    # Removed 'if current_eval_len_for_window > 0:'\n",
        "    true_eval_cluster_returns_raw = _calculate_weighted_cluster_returns_functional(\n",
        "        data_slice_for_returns_calc=actual_eval_asset_returns_item,\n",
        "        data_slice_for_centroid_weights_calc=lookback_asset_returns_item,\n",
        "        cluster_definitions=cluster_defs,\n",
        "        cluster_names_ordered=cluster_names_ord,\n",
        "        sigma_for_weights=sigma_for_weights_static\n",
        "    )\n",
        "\n",
        "    pnl_c_tensor = calculate_pnl_torch(forecasted_cluster_returns_raw, true_eval_cluster_returns_raw)\n",
        "    # Removed 'if pnl_c_tensor.numel() > 0:'\n",
        "    pnl_c_val = pnl_c_tensor.mean().to(torch.float32)\n",
        "    # Removed 'if torch.isnan(pnl_c_val):'\n",
        "\n",
        "    pnl_n_val = torch.tensor(0.0, dtype=torch.float32, device=device_static)\n",
        "    forecasted_naive_returns_raw = torch.tensor(0.0, dtype=torch.float32, device=device_static)\n",
        "    true_eval_naive_returns_raw = torch.tensor(0.0, dtype=torch.float32, device=device_static)\n",
        "\n",
        "    if run_naive_var_comparison_static:\n",
        "        # Removed 'if lookback_asset_returns_item.numel() > 0 and lookback_asset_returns_item.shape[1] > 0 :'\n",
        "        forecasted_naive_returns_raw = _fit_var_and_forecast_functional(\n",
        "            lookback_asset_returns_item, num_assets_overall_static, var_order_static,\n",
        "            current_eval_len_for_window, device_static\n",
        "        )\n",
        "\n",
        "        # Removed 'if current_eval_len_for_window > 0:'\n",
        "        true_eval_naive_returns_raw = actual_eval_asset_returns_item\n",
        "\n",
        "        pnl_n_tensor = calculate_pnl_torch(forecasted_naive_returns_raw, forecasted_naive_returns_raw)\n",
        "        # Removed 'if pnl_n_tensor.numel() > 0:'\n",
        "        pnl_n_val = pnl_n_tensor.mean().to(torch.float32)\n",
        "        # Removed 'if torch.isnan(pnl_n_val):'\n",
        "\n",
        "    return (pnl_c_val, forecasted_cluster_returns_raw, true_eval_cluster_returns_raw,\n",
        "            pnl_n_val, forecasted_naive_returns_raw, true_eval_naive_returns_raw,\n",
        "            window_idx_batch\n",
        "           )\n",
        "\n",
        "# --- REFACTORED Main sliding window function ---\n",
        "def run_sliding_window_var_evaluation_vmap(\n",
        "    asset_returns_tensor, initial_lookback_len, eval_len, n_clusters_config,\n",
        "    cluster_method, var_order, sigma_intra_cluster, num_windows,\n",
        "    device=None, store_sample_forecasts=True, run_naive_var_comparison=True\n",
        "):\n",
        "    # Removed 'if device is None:' device will be asset_returns_tensor.device if not passed\n",
        "    effective_device = device if device is not None else asset_returns_tensor.device\n",
        "\n",
        "    num_assets_overall = asset_returns_tensor.shape[1]\n",
        "    tensor_total_len = asset_returns_tensor.shape[0]\n",
        "\n",
        "    base_lookback_start_indices = torch.arange(num_windows, device=effective_device) * eval_len\n",
        "    base_lookback_end_indices = base_lookback_start_indices + initial_lookback_len\n",
        "\n",
        "    valid_mask_initial = (base_lookback_end_indices <= tensor_total_len) & \\\n",
        "                         (base_lookback_end_indices < tensor_total_len)\n",
        "\n",
        "    filtered_lb_start_indices = base_lookback_start_indices[valid_mask_initial]\n",
        "    filtered_lb_end_indices = base_lookback_end_indices[valid_mask_initial]\n",
        "    original_window_indices_filtered = torch.arange(num_windows, device=effective_device)[valid_mask_initial]\n",
        "\n",
        "    # Removed 'if len(filtered_lb_start_indices) == 0:' and early return\n",
        "\n",
        "    num_potentially_valid_windows = len(filtered_lb_start_indices)\n",
        "    current_eval_lens_for_filtered = torch.full((num_potentially_valid_windows,), eval_len, dtype=torch.long, device=effective_device)\n",
        "    for i in range(num_potentially_valid_windows): # This loop might be empty if num_potentially_valid_windows is 0\n",
        "        max_possible_eval_len = tensor_total_len - filtered_lb_end_indices[i]\n",
        "        current_eval_lens_for_filtered[i] = min(eval_len, max_possible_eval_len)\n",
        "\n",
        "    valid_mask_eval_len = current_eval_lens_for_filtered > 0\n",
        "\n",
        "    final_lookback_start_indices = filtered_lb_start_indices[valid_mask_eval_len]\n",
        "    final_lookback_end_indices = filtered_lb_end_indices[valid_mask_eval_len]\n",
        "    final_current_eval_lens = current_eval_lens_for_filtered[valid_mask_eval_len]\n",
        "    final_original_window_indices_batch = original_window_indices_filtered[valid_mask_eval_len]\n",
        "\n",
        "    # Removed 'if len(final_lookback_start_indices) == 0:' and early return\n",
        "\n",
        "    actual_num_windows_to_process = len(final_lookback_start_indices)\n",
        "\n",
        "    batched_lookback_slices = []\n",
        "    batched_eval_slices_padded = []\n",
        "\n",
        "    # for _ in repeat_for_robustness:\n",
        "    #   for p in lag_orders_to_test:\n",
        "    #       for k in num_clusters_to_test:\n",
        "    for s in range(actual_num_windows_to_process): # This loop might be empty\n",
        "        start = final_lookback_start_indices[s]\n",
        "        end = final_lookback_end_indices[s]\n",
        "\n",
        "        lb_slice = asset_returns_tensor[start:end, :]\n",
        "        batched_lookback_slices.append(lb_slice)\n",
        "\n",
        "        eval_s = end\n",
        "        current_L = final_current_eval_lens[s].item()\n",
        "        eval_e = eval_s + current_L\n",
        "        ev_slice_actual = asset_returns_tensor[eval_s:eval_e, :]\n",
        "\n",
        "        # # Padding logic kept for vmap compatibility\n",
        "        # if current_L < eval_len:\n",
        "        #     padding = torch.zeros((eval_len - current_L, num_assets_overall),\n",
        "        #                           dtype=asset_returns_tensor.dtype, device=effective_device)\n",
        "        #     ev_slice_padded = torch.cat([ev_slice_actual, padding], dim=0)\n",
        "        # elif current_L == eval_len:\n",
        "        #     ev_slice_padded = ev_slice_actual\n",
        "        # else:\n",
        "        #     ev_slice_padded = ev_slice_actual[:eval_len,:]\n",
        "\n",
        "        batched_eval_slices_padded.append(ev_slice_actual)\n",
        "\n",
        "    # These stacks will error if their respective lists are empty (e.g., actual_num_windows_to_process is 0)\n",
        "    final_batched_lookback_data = torch.stack(batched_lookback_slices)\n",
        "    final_batched_eval_data_padded = torch.stack(batched_eval_slices_padded)\n",
        "\n",
        "\n",
        "    vmapped_processor = func.vmap(\n",
        "        single_window_iteration_processor_refactored,\n",
        "        in_dims=(0, 0, None, 0,\n",
        "                   None, None, None, None, None, None, None, None),\n",
        "        out_dims=0, randomness='different'\n",
        "    )\n",
        "\n",
        "    all_pnl_c_vals, all_forecast_c, all_actual_c, \\\n",
        "    all_pnl_n_vals, all_forecast_n, all_actual_n, \\\n",
        "    processed_window_indices = vmapped_processor(\n",
        "        final_batched_lookback_data,\n",
        "        final_batched_eval_data_padded,\n",
        "        eval_len,\n",
        "        final_original_window_indices_batch,\n",
        "        n_clusters_config,\n",
        "        cluster_method,\n",
        "        var_order,\n",
        "        sigma_intra_cluster,\n",
        "        eval_len,\n",
        "        run_naive_var_comparison,\n",
        "        num_assets_overall,\n",
        "        effective_device\n",
        "    )\n",
        "\n",
        "    all_window_pnl_cluster_dicts = []\n",
        "    all_window_pnl_naive_dicts = []\n",
        "\n",
        "    for i in range(actual_num_windows_to_process): # This loop might be empty\n",
        "        win_id = processed_window_indices[i].item()\n",
        "\n",
        "        # Removed filter 'if all_pnl_c_vals[i].item() != 0.0 or all_forecast_c[i].abs().sum() > 1e-9:'\n",
        "        all_window_pnl_cluster_dicts.append({\n",
        "             'Window_ID': win_id, 'Avg_Window_PNL': all_pnl_c_vals[i].item(),\n",
        "             'VAR_Order': var_order, 'Method': 'Clustered VAR'\n",
        "         })\n",
        "\n",
        "        if run_naive_var_comparison:\n",
        "            # Removed filter for naive pnl/forecast values\n",
        "            all_window_pnl_naive_dicts.append({\n",
        "                'Window_ID': win_id, 'Avg_Window_PNL': all_pnl_n_vals[i].item(),\n",
        "                'VAR_Order': var_order, 'Method': 'Naive VAR'\n",
        "            })\n",
        "\n",
        "    sample_forecast_c, sample_actual_c, sample_win_idx = None, None, -1\n",
        "    # Removed 'and actual_num_windows_to_process > 0' from condition\n",
        "    if store_sample_forecasts:\n",
        "        sample_idx_in_batch = 0 # Will error if actual_num_windows_to_process is 0\n",
        "        actual_eval_len_for_sample = final_current_eval_lens[sample_idx_in_batch].item()\n",
        "\n",
        "        sample_forecast_c = all_forecast_c[sample_idx_in_batch, :actual_eval_len_for_sample, :].clone()\n",
        "        sample_actual_c = all_actual_c[sample_idx_in_batch, :actual_eval_len_for_sample, :].clone()\n",
        "        sample_win_idx = processed_window_indices[sample_idx_in_batch].item()\n",
        "\n",
        "    return {\n",
        "        'cluster_avg_pnl_list': all_window_pnl_cluster_dicts,\n",
        "        'naive_avg_pnl_list': all_window_pnl_naive_dicts,\n",
        "        'sample_forecast_cluster': sample_forecast_c,\n",
        "        'sample_actual_cluster': sample_actual_c,\n",
        "        'sample_window_idx_cluster': sample_win_idx,\n",
        "        'var_order_for_sample': var_order\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data loaded and cleaned. Sample (first 5 rows/cols):\n",
            "ticker            AA       ABM       ABT       ADI       ADM\n",
            "2000-01-03 -0.013042 -0.009188 -0.007117 -0.036071  0.000000\n",
            "2000-01-04  0.010043  0.012346 -0.012786 -0.044261  0.005277\n",
            "2000-01-05  0.047628 -0.006192  0.011111  0.014493 -0.015915\n",
            "2000-01-06 -0.011713  0.000000  0.032553 -0.027719  0.010695\n",
            "2000-01-07 -0.016118  0.003091  0.028573  0.033654  0.005249\n",
            "Shape of the cleaned data: (5279, 663)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "VAR Order Grid Search:   0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running k-means on cuda..\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "VAR Order Grid Search:   0%|          | 0/3 [00:03<?, ?it/s]\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "vmap: We do not support batching operators that can output dynamic shape. Attempted to vmap over aten::nonzero. Please voice your support in https://github.com/pytorch/functorch/issues/256",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[3], line 46\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Removed dummy data definition block for testing as it's a form of edge case / setup handling.\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# The script now assumes 'historical_data_tensor' and 'device' are correctly defined.\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# if 'historical_data_tensor' not in globals() or 'device' not in globals():\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m#    ...\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Removed 'if historical_data_tensor.numel() > 0:'\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var_order_val \u001b[38;5;129;01min\u001b[39;00m tqdm(var_orders_to_test_config, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVAR Order Grid Search\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 46\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_sliding_window_var_evaluation_vmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43masset_returns_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistorical_data_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Will error if not defined or empty and used inappropriately by functions\u001b[39;49;00m\n\u001b[0;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43minitial_lookback_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_lookback_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevaluation_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_clusters_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_clusters_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcluster_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcluster_method_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvar_order\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvar_order_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43msigma_intra_cluster\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msigma_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_windows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_windows_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstore_sample_forecasts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvar_order_val\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvar_orders_to_test_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_naive_var_comparison\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m     all_lags_combined_pnl_data\u001b[38;5;241m.\u001b[39mextend(results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster_avg_pnl_list\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     60\u001b[0m     all_lags_combined_pnl_data\u001b[38;5;241m.\u001b[39mextend(results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnaive_avg_pnl_list\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
            "Cell \u001b[1;32mIn[2], line 163\u001b[0m, in \u001b[0;36mrun_sliding_window_var_evaluation_vmap\u001b[1;34m(asset_returns_tensor, initial_lookback_len, eval_len, n_clusters_config, cluster_method, var_order, sigma_intra_cluster, num_windows, device, store_sample_forecasts, run_naive_var_comparison)\u001b[0m\n\u001b[0;32m    151\u001b[0m final_batched_eval_data_padded \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(batched_eval_slices_padded)\n\u001b[0;32m    154\u001b[0m vmapped_processor \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39mvmap(\n\u001b[0;32m    155\u001b[0m     single_window_iteration_processor_refactored,\n\u001b[0;32m    156\u001b[0m     in_dims\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    157\u001b[0m                \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    158\u001b[0m     out_dims\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, randomness\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferent\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    159\u001b[0m )\n\u001b[0;32m    161\u001b[0m all_pnl_c_vals, all_forecast_c, all_actual_c, \\\n\u001b[0;32m    162\u001b[0m all_pnl_n_vals, all_forecast_n, all_actual_n, \\\n\u001b[1;32m--> 163\u001b[0m processed_window_indices \u001b[38;5;241m=\u001b[39m \u001b[43mvmapped_processor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfinal_batched_lookback_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfinal_batched_eval_data_padded\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfinal_original_window_indices_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_clusters_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcluster_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvar_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[43msigma_intra_cluster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_naive_var_comparison\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_assets_overall\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43meffective_device\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    178\u001b[0m all_window_pnl_cluster_dicts \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    179\u001b[0m all_window_pnl_naive_dicts \u001b[38;5;241m=\u001b[39m []\n",
            "File \u001b[1;32mc:\\Users\\niloz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_functorch\\apis.py:202\u001b[0m, in \u001b[0;36mvmap.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvmap_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\niloz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_functorch\\vmap.py:334\u001b[0m, in \u001b[0;36mvmap_impl\u001b[1;34m(func, in_dims, out_dims, randomness, chunk_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _chunked_vmap(\n\u001b[0;32m    324\u001b[0m         func,\n\u001b[0;32m    325\u001b[0m         flat_in_dims,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    331\u001b[0m     )\n\u001b[0;32m    333\u001b[0m \u001b[38;5;66;03m# If chunk_size is not specified.\u001b[39;00m\n\u001b[1;32m--> 334\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_flat_vmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_in_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\niloz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_functorch\\vmap.py:484\u001b[0m, in \u001b[0;36m_flat_vmap\u001b[1;34m(func, batch_size, flat_in_dims, flat_args, args_spec, out_dims, randomness, **kwargs)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m vmap_increment_nesting(batch_size, randomness) \u001b[38;5;28;01mas\u001b[39;00m vmap_level:\n\u001b[0;32m    481\u001b[0m     batched_inputs \u001b[38;5;241m=\u001b[39m _create_batched_inputs(\n\u001b[0;32m    482\u001b[0m         flat_in_dims, flat_args, vmap_level, args_spec\n\u001b[0;32m    483\u001b[0m     )\n\u001b[1;32m--> 484\u001b[0m     batched_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatched_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    485\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unwrap_batched(batched_outputs, out_dims, vmap_level, batch_size, func)\n",
            "Cell \u001b[1;32mIn[2], line 18\u001b[0m, in \u001b[0;36msingle_window_iteration_processor_refactored\u001b[1;34m(lookback_asset_returns_item, eval_asset_returns_item_padded, current_eval_len_for_window, window_idx_batch, initial_n_clusters_config_static, cluster_method_static, var_order_static, sigma_for_weights_static, max_eval_len_static, run_naive_var_comparison_static, num_assets_overall_static, device_static)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msingle_window_iteration_processor_refactored\u001b[39m(\n\u001b[0;32m      3\u001b[0m     lookback_asset_returns_item,\n\u001b[0;32m      4\u001b[0m     eval_asset_returns_item_padded,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     device_static\n\u001b[0;32m     15\u001b[0m ):\n\u001b[0;32m     16\u001b[0m     actual_eval_asset_returns_item \u001b[38;5;241m=\u001b[39m eval_asset_returns_item_padded\n\u001b[1;32m---> 18\u001b[0m     cluster_defs, cluster_names_ord, actual_n_clust_formed, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_define_clusters_and_centroids_functional\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlookback_asset_returns_item\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_n_clusters_config_static\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcluster_method_static\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_static\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# Removed 'if cluster_names_ord:'\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     lookback_cluster_returns \u001b[38;5;241m=\u001b[39m _calculate_weighted_cluster_returns_functional(\n\u001b[0;32m     24\u001b[0m         data_slice_for_returns_calc\u001b[38;5;241m=\u001b[39mlookback_asset_returns_item,\n\u001b[0;32m     25\u001b[0m         data_slice_for_centroid_weights_calc\u001b[38;5;241m=\u001b[39mlookback_asset_returns_item,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     28\u001b[0m         sigma_for_weights\u001b[38;5;241m=\u001b[39msigma_for_weights_static\n\u001b[0;32m     29\u001b[0m     )\n",
            "File \u001b[1;32mn:\\GitHub\\ICAIF_25\\Code\\Main_modules\\PnL_utilities.py:80\u001b[0m, in \u001b[0;36m_define_clusters_and_centroids_functional\u001b[1;34m(asset_returns_lookback_tensor, initial_n_clusters_config, cluster_method, device_param)\u001b[0m\n\u001b[0;32m     76\u001b[0m output_corr_matrix \u001b[38;5;241m=\u001b[39m asset_corr_matrix \u001b[38;5;66;03m# Default, may be overwritten\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# Removed num_assets == 0 check\u001b[39;00m\n\u001b[1;32m---> 80\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43m_apply_clustering_algorithm_functional\u001b[49m\u001b[43m(\u001b[49m\u001b[43masset_corr_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_n_clusters_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcluster_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mderived_device\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# def handmade_unique(x):\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m#   sorted_x, _ = torch.sort(x)\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m#   mask = (sorted_x[1:] - sorted_x[:-1])>0\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# unique_labels = torch.nonzero(unique_labels, as_tuple=False).squeeze()\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# print(unique_labels)\u001b[39;00m\n\u001b[0;32m     89\u001b[0m centroids_to_cat \u001b[38;5;241m=\u001b[39m []\n",
            "File \u001b[1;32mn:\\GitHub\\ICAIF_25\\Code\\Main_modules\\PnL_utilities.py:61\u001b[0m, in \u001b[0;36m_apply_clustering_algorithm_functional\u001b[1;34m(correlation_matrix_tensor, num_clusters_to_form, cluster_method, device_param)\u001b[0m\n\u001b[0;32m     59\u001b[0m     pos_corr \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(correlation_matrix_tensor, \u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     60\u001b[0m     neg_corr \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mabs(torch\u001b[38;5;241m.\u001b[39mclamp(correlation_matrix_tensor, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m---> 61\u001b[0m     labels, _ \u001b[38;5;241m=\u001b[39m \u001b[43mspectral_clustering_laplacian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos_corr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneg_corr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_n_clusters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported cluster_method: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcluster_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mn:\\GitHub\\ICAIF_25\\Code\\Main_modules\\PnL_utilities.py:22\u001b[0m, in \u001b[0;36mspectral_clustering_laplacian\u001b[1;34m(p, n, k)\u001b[0m\n\u001b[0;32m     18\u001b[0m w, v \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39meigh(matrix)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# u = v[:, :k]\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# # normalize the rows to have unit 2-norm\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# t = u / u.norm(dim=1, keepdim=True)\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mkmeans\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\niloz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\kmeans_pytorch\\__init__.py:63\u001b[0m, in \u001b[0;36mkmeans\u001b[1;34m(X, num_clusters, distance, tol, device)\u001b[0m\n\u001b[0;32m     60\u001b[0m initial_state_pre \u001b[38;5;241m=\u001b[39m initial_state\u001b[38;5;241m.\u001b[39mclone()\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_clusters):\n\u001b[1;32m---> 63\u001b[0m     selected \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnonzero\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchoice_cluster\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     65\u001b[0m     selected \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mindex_select(X, \u001b[38;5;241m0\u001b[39m, selected)\n\u001b[0;32m     66\u001b[0m     initial_state[index] \u001b[38;5;241m=\u001b[39m selected\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
            "\u001b[1;31mRuntimeError\u001b[0m: vmap: We do not support batching operators that can output dynamic shape. Attempted to vmap over aten::nonzero. Please voice your support in https://github.com/pytorch/functorch/issues/256"
          ]
        }
      ],
      "source": [
        "\"\"\"## 1. Load and Clean Data\"\"\"\n",
        "\n",
        "# file_path = r'OPCL_20000103_20201231.csv' # Path to your data file\n",
        "file_path = r'N:\\GitHub\\ICAIF_25\\Data\\OPCL_20000103_20201231.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "device = 'cuda:0'\n",
        "\n",
        "# Removed 'if not df.empty:' checks. Code will error if df is empty and operations are called.\n",
        "df.set_index('ticker', inplace=True)\n",
        "df.columns = pd.to_datetime(df.columns.str.lstrip('X'), format='%Y%m%d').strftime('%Y-%m-%d')\n",
        "df_cleaned = df.dropna().transpose()\n",
        "df_cleaned.index = pd.to_datetime(df_cleaned.index)\n",
        "print(\"Data loaded and cleaned. Sample (first 5 rows/cols):\")\n",
        "# This print will error if df_cleaned is too small or empty.\n",
        "print(df_cleaned.iloc[0:5,0:5])\n",
        "\n",
        "print(f\"Shape of the cleaned data: {df_cleaned.shape}\")\n",
        "\n",
        "numpy_array = df_cleaned.astype(float).values\n",
        "historical_data_tensor = torch.from_numpy(numpy_array).float()\n",
        "historical_data_tensor = historical_data_tensor.to(device)\n",
        "# historical_data_tensor = torch.log1p(historical_data_tensor)\n",
        "\"\"\"## 2. VAR Lag Grid Search and Evaluation\"\"\"\n",
        "\n",
        "##################################################################### PARAMETERS #####################################################################\n",
        "initial_lookback_len = 252\n",
        "evaluation_len = 5\n",
        "num_clusters_config = 20\n",
        "cluster_method_config = 'spectral_clustering'\n",
        "sigma_config = 0.5\n",
        "num_windows_config = 25\n",
        "var_orders_to_test_config = range(5,11,2)\n",
        "####################################################################################################################################################\n",
        "\n",
        "all_lags_combined_pnl_data = []\n",
        "final_sample_details = {}\n",
        "\n",
        "# Removed dummy data definition block for testing as it's a form of edge case / setup handling.\n",
        "# The script now assumes 'historical_data_tensor' and 'device' are correctly defined.\n",
        "# if 'historical_data_tensor' not in globals() or 'device' not in globals():\n",
        "#    ...\n",
        "\n",
        "# Removed 'if historical_data_tensor.numel() > 0:'\n",
        "for var_order_val in tqdm(var_orders_to_test_config, desc=\"VAR Order Grid Search\"):\n",
        "    results = run_sliding_window_var_evaluation_vmap(\n",
        "        asset_returns_tensor=historical_data_tensor, # Will error if not defined or empty and used inappropriately by functions\n",
        "        initial_lookback_len=initial_lookback_len,\n",
        "        eval_len=evaluation_len,\n",
        "        n_clusters_config=num_clusters_config,\n",
        "        cluster_method=cluster_method_config,\n",
        "        var_order=var_order_val,\n",
        "        sigma_intra_cluster=sigma_config,\n",
        "        num_windows=num_windows_config,\n",
        "        device=device,\n",
        "        store_sample_forecasts=(var_order_val == var_orders_to_test_config[-1]),\n",
        "        run_naive_var_comparison=False\n",
        "    )\n",
        "    all_lags_combined_pnl_data.extend(results['cluster_avg_pnl_list'])\n",
        "    all_lags_combined_pnl_data.extend(results['naive_avg_pnl_list'])\n",
        "\n",
        "    # Removed 'and results.get('sample_forecast_cluster') is not None'\n",
        "    if (var_order_val == var_orders_to_test_config[-1]):\n",
        "        final_sample_details = results # Will store even if sample is None\n",
        "\n",
        "print(\"\\n--- Grid Search Completed ---\")\n",
        "# Removed 'if all_lags_combined_pnl_data:'\n",
        "agg_data = {}\n",
        "methods_seen = set()\n",
        "for record in all_lags_combined_pnl_data: # Will error if all_lags_combined_pnl_data is empty but accessed.\n",
        "    methods_seen.add(record['Method'])\n",
        "    key = (record['VAR_Order'], record['Method'])\n",
        "    agg_data.setdefault(key, []).append(record['Avg_Window_PNL'])\n",
        "\n",
        "sorted_methods = sorted(list(methods_seen))\n",
        "# Removed 'if not sorted_methods:'\n",
        "header = f\"{'VAR_Order':<10} | \" + \" | \".join([f\"{m:<15}\" for m in sorted_methods])\n",
        "print(\"\\nAverage Window PNL per Lag Order and Method:\")\n",
        "print(header)\n",
        "print(\"-\" * len(header))\n",
        "\n",
        "for var_order in sorted(list(set(r['VAR_Order'] for r in all_lags_combined_pnl_data))):\n",
        "    row_str = f\"{var_order:<10} | \"\n",
        "    for method in sorted_methods:\n",
        "        pnl_list = agg_data.get((var_order, method), []) # Keep .get for safety or it could KeyError\n",
        "        # Removed 'if pnl_list:' for calculating avg_pnl. Division by zero if len is 0.\n",
        "        avg_pnl = sum(pnl_list) / len(pnl_list) if pnl_list else float('nan') # Retained minimal check to avoid div by zero for print\n",
        "        row_str += f\"{avg_pnl:<15.6f} | \"\n",
        "    print(row_str.strip().rsplit('|', 1)[0].strip())\n",
        "\n",
        "\n",
        "# 3. Visualization\n",
        "# Removed 'if all_lags_combined_pnl_data:'\n",
        "# Removed 'try-except' block for plotting\n",
        "# Filter for valid numeric PNLs for plotting to prevent seaborn/matplotlib errors. This is a practical necessity for plotting.\n",
        "plot_data_list = [d for d in all_lags_combined_pnl_data if isinstance(d.get('Avg_Window_PNL'), (int, float)) and not np.isnan(d.get('Avg_Window_PNL'))]\n",
        "\n",
        "# Removed 'if plot_data_list:'\n",
        "plot_df_data = {\n",
        "    'VAR_Order': [d['VAR_Order'] for d in plot_data_list],\n",
        "    'Avg_Window_PNL': [d['Avg_Window_PNL'] for d in plot_data_list],\n",
        "    'Method': [d['Method'] for d in plot_data_list]\n",
        "}\n",
        "plt.figure(figsize=(14, 8))\n",
        "sns.boxplot(x='VAR_Order', y='Avg_Window_PNL', hue='Method', data=plot_df_data) # Will error if plot_df_data is empty/malformed\n",
        "plt.title('Distribution of Avg Window PNL by VAR Lag & Method (PyTorch with vmap)')\n",
        "plt.xlabel('VAR Lag Order'); plt.ylabel('Avg Window PNL')\n",
        "plt.legend(title='Forecast Method'); plt.grid(True, axis='y', alpha=0.7)\n",
        "plt.tight_layout(); plt.show()\n",
        "\n",
        "\n",
        "# Removed 'if final_sample_details and final_sample_details.get('sample_forecast_cluster') is not None:'\n",
        "# Direct access, will error if keys don't exist or values are None and methods are called.\n",
        "fc = final_sample_details['sample_forecast_cluster'].cpu().numpy()\n",
        "ac = final_sample_details['sample_actual_cluster'].cpu().numpy()\n",
        "win_idx = final_sample_details['sample_window_idx_cluster']\n",
        "var_ord_sample = final_sample_details['var_order_for_sample']\n",
        "\n",
        "print(f\"\\n--- Plotting Sample: Window {win_idx + 1 if win_idx != -1 else 'N/A'}, Clustered VAR Lag {var_ord_sample} ---\")\n",
        "num_series_to_plot = min(3, fc.shape[1]) # fc.shape[1] will error if fc is None\n",
        "# Removed 'if num_series_to_plot == 0:'\n",
        "\n",
        "for i in range(num_series_to_plot):\n",
        "    plt.figure(figsize=(14, 7))\n",
        "    # Removed data/length validation before plotting. Plotting functions might error.\n",
        "    sns.lineplot(x=range(len(ac[:, i])), y=ac[:, i], label=f'Actual Cluster {i+1}', marker='o')\n",
        "    sns.lineplot(x=range(len(fc[:, i])), y=fc[:, i], label=f'Forecast Cluster {i+1}', marker='x', linestyle='--')\n",
        "    plt.title(f'Prediction vs Actual for Cluster {i+1} (Win {win_idx+1 if win_idx != -1 else \"N/A\"}, VAR {var_ord_sample}, PyTorch with vmap)')\n",
        "    plt.xlabel('Forecast Step'); plt.ylabel('Cluster Return')\n",
        "    plt.legend(); plt.grid(True); plt.tight_layout(); plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
