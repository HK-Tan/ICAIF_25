{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symetric Normalized version of SPONGE (Signed Positive Over Negative Generalized Eigenproblem)\n",
    "\n",
    "We cluster using signed Signed Positive Over Negative Generalized Eigenproblem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no NaN values in the dataframe\n"
     ]
    }
   ],
   "source": [
    "# Function to safely convert a string into a list\n",
    "def safe_literal_eval(s):\n",
    "    try:\n",
    "        # Tries to convert the string into a list\n",
    "        return ast.literal_eval(s)\n",
    "    except (ValueError, SyntaxError):\n",
    "        # If an error occurs, returns a default value, e.g. an empty list\n",
    "        return []\n",
    "\n",
    "def check_nan_inf(df):\n",
    "    # Vérification des valeurs NaN\n",
    "    if df.isna().any().any():\n",
    "        print(\"There are NaN values in the dataframe\")\n",
    "    else:\n",
    "        print(\"There are no NaN values in the dataframe\")\n",
    "\n",
    "def remove_rows_with_nan(df):\n",
    "    return df.dropna()\n",
    "\n",
    "def load_cleaned_data(path):\n",
    "    '''\n",
    "    ----------------------------------------------------------------\n",
    "    PARAMETERS : path = string\n",
    "    ----------------------------------------------------------------\n",
    "    '''\n",
    "    df = pd.read_csv(path) \n",
    "\n",
    "    # Apply conversion function to 'open' and 'close' columns\n",
    "    df['open'] = df['open'].apply(safe_literal_eval)\n",
    "    df['close'] = df['close'].apply(safe_literal_eval)\n",
    "\n",
    "    # Calculate returns for each line\n",
    "    df['return'] = df.apply(lambda row: [(close - open) / open for open, close in zip(row['open'], row['close'])], axis=1)\n",
    "\n",
    "    # create a new data frame with the column ticker and return \n",
    "    new_df = df[['ticker', 'return']] \n",
    "\n",
    "    # Convertir chaque liste dans la colonne 'return' en plusieurs colonnes dans le nouveau DataFrame\n",
    "    returns_df = pd.DataFrame(new_df['return'].tolist())\n",
    "\n",
    "    # Ajouter la colonne 'ticker' du 'new_df' au début de 'returns_df'\n",
    "    returns_df.insert(0, 'ticker', new_df['ticker'])\n",
    "\n",
    "    # Renommer les colonnes pour refléter qu'elles sont des rendements\n",
    "    returns_df.columns = ['ticker'] + [f'return_{i}' for i in range(len(returns_df.columns) - 1)]\n",
    "\n",
    "    df_cleaned = remove_rows_with_nan(returns_df)\n",
    "    df_cleaned.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    check_nan_inf(df_cleaned)\n",
    "\n",
    "    return df_cleaned\n",
    "\n",
    "# Put your own path \n",
    "# Nail path : '/Users/khelifanail/Documents/GitHub/Portfolio_clustering_project/Data/DATA_Statapp.csv'\n",
    "# Jerome path : 'C:\\Users\\33640\\OneDrive\\Documents\\GitHub\\Portfolio_clustering_project\\Data\\DATA_Statapp.csv'\n",
    "\n",
    "nail_path = '/Users/khelifanail/Documents/GitHub/Portfolio_clustering_project/Data/DATA_Statapp.csv'\n",
    "df_cleaned = load_cleaned_data(nail_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get a clustering with SPONGE algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "## path Nail : '/Users/khelifanail/Documents/GitHub/Portfolio_clustering_project'\n",
    "## path Jerome : 'C:/Users/33640/OneDrive/Documents/GitHub/Portfolio_clustering_project'\n",
    "sys.path.append('/Users/khelifanail/Documents/GitHub/Portfolio_clustering_project')  # Ajoute le chemin parent\n",
    "\n",
    "from signet.cluster import Cluster \n",
    "from scipy import sparse\n",
    "def signed_adjency(mat):\n",
    "    '''\n",
    "    L'idée est ici, à partir d'une matrice de corrélation mat, de renvoyer deux matrices \n",
    "    A_positive et A_negative qui correspondraient aux matrices des corrélations positives et négatives \n",
    "    associées  \n",
    "    '''\n",
    "\n",
    "    A_pos = mat.applymap(lambda x: x if x >= 0 else 0)\n",
    "    A_neg = mat.applymap(lambda x: abs(x) if x < 0 else 0)\n",
    "    \n",
    "    return A_pos, A_neg\n",
    "def apply_SPONGE(correlation_matrix, k): \n",
    "\n",
    "    '''\n",
    "    IDÉE : étant donné une matrice de correlation obtenue à partir d'une base de donnée et de la similarité de pearson, renvoyer un vecteur associant \n",
    "           à chaque actif le numéro du cluster auquel il appartient une fois qu'on lui a appliqué SPONGE (à partir du package signet)\n",
    "\n",
    "    PARAMS : \n",
    "\n",
    "    - correlation_matrix : a square dataframe of size (number_of_stocks, number_of_stocks)\n",
    "    - k : the number of clusters to identify. If a list is given, the output is a corresponding list\n",
    "\n",
    "    RETURNS : array of int, or list of array of int: Output assignment to clusters.\n",
    "\n",
    "    '''\n",
    "    \n",
    "    ## On respecte le format imposé par signet. Pour cela il faut changer le type des matrices A_pos et A_neg, qui ne peuvent pas rester des dataframes \n",
    "\n",
    "    A_pos, A_neg = signed_adjency(correlation_matrix)\n",
    "\n",
    "    A_pos_sparse = sparse.csc_matrix(A_pos.values)\n",
    "    A_neg_sparse = sparse.csc_matrix(A_neg.values)\n",
    "\n",
    "    data = (A_pos_sparse, A_neg_sparse)\n",
    "\n",
    "    cluster = Cluster(data)\n",
    "\n",
    "    ## On applique la méthode SPONGE : clusters the graph using the Signed Positive Over Negative Generalised Eigenproblem (SPONGE) clustering.\n",
    "\n",
    "    return cluster.SPONGE(k )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
