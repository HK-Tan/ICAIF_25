{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import process\n",
    "import numpy as np \n",
    "# Jerome path : r'C:\\Users\\33640\\OneDrive\\Documents\\GitHub\\Portfolio_clustering_project\\Data\\DataBase.csv'\n",
    "# Nail path : '/Users/khelifanail/Documents/GitHub/Portfolio_clustering_project/Data/DataBase.csv'\n",
    "df = pd.read_csv(r'/Users/khelifanail/Documents/GitHub/Portfolio_clustering_project/Data/DataBase.csv')\n",
    "\n",
    "df.set_index('ticker', inplace=True)\n",
    "\n",
    "df.columns = pd.to_datetime(df.columns.str[1:], format='%Y%m%d').strftime('%d/%m/%Y')\n",
    "\n",
    "df_cleaned = df.fillna(0) # Utilisez la m√©thode fillna(0) pour remplacer les NaN par 0\n",
    "\n",
    "df_cleaned = df_cleaned.transpose() ## WE WANT COLUMNS TO BE VECTOR OF RETURN FOR A GIVEN TICKER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "\n",
    "def cov_forecast(beta, lookback_window, number_folds, historical_data):\n",
    "\n",
    "    N = len(historical_data.columns)  # Number of assets, BEWARE TO THE SHAPE OF THE DATA FOR\n",
    "\n",
    "    Ik_length = int((lookback_window[1]-lookback_window[0])/number_folds) # Number of days in each fold for the cross validation, has to be an integer\n",
    "\n",
    "    # Initialize epsilon as a zero array with N elements\n",
    "    epsilon = np.zeros(N)\n",
    "\n",
    "    for k in range(number_folds):\n",
    "        # Calculate EWA matrix \n",
    "        weighted_matrices = [(beta**(Ik_length-t)) * np.outer(historical_data.iloc[t + Ik_length*k], historical_data.iloc[t + Ik_length*k]) for t in range(Ik_length)]\n",
    "        summed_weighted_matrices = np.sum(weighted_matrices, axis=0)\n",
    "        E_matrix = (1 - beta) / (1 - beta**Ik_length) * summed_weighted_matrices\n",
    "        \n",
    "        # Calculate eigenvectors for the E matrix\n",
    "        eigenvalues, eigenvectors = np.linalg.eigh(E_matrix)\n",
    "\n",
    "        # Calculate epsilon terms for each eigenvector\n",
    "        for i in range(N):\n",
    "            ui = eigenvectors[:, i]\n",
    "            # For each day in the Ik segment, project the data onto the eigenvector and square it\n",
    "            epsilon_i_sum = np.sum([(np.dot(ui, historical_data.iloc[t + Ik_length*k])**2) for t in range(Ik_length)])\n",
    "            # Accumulate the results in epsilon\n",
    "            epsilon[i] += epsilon_i_sum.real / Ik_length\n",
    "\n",
    "    # Average epsilon over K segments\n",
    "    epsilon /= number_folds\n",
    "\n",
    "    # Now, we calculate the forecasts using the last set of eigenvectors\n",
    "    cov = pd.DataFrame(index=historical_data.columns, columns=historical_data.columns, data=np.sum([epsilon[i] * np.outer(eigenvectors[:, i], eigenvectors[:, i]) for i in range(N)], axis=0)).fillna(0.)\n",
    "\n",
    "    return cov\n",
    "\n",
    "def portfolio_returns(historical_data, evaluation_window, lookback_window, cov, eta, short_selling=True):\n",
    "\n",
    "    ## we compute the markowitz weights using this forecast\n",
    "\n",
    "    expected_returns = process.noised_array(y=historical_data.iloc[200,:], eta=eta)\n",
    "\n",
    "    if short_selling:\n",
    "\n",
    "        ef = EfficientFrontier(expected_returns=expected_returns, cov_matrix=cov, weight_bounds=(-1, 1))\n",
    "\n",
    "    else:\n",
    "\n",
    "        ef = EfficientFrontier(expected_returns=expected_returns, cov_matrix=cov, weight_bounds=(0, 1))\n",
    "\n",
    "    ef.efficient_return(target_return=expected_returns.mean())\n",
    "\n",
    "    markowitz_weights = ef.clean_weights()\n",
    "\n",
    "    portfolio_returns = pd.DataFrame(index=df_cleaned.iloc[lookback_window[1]:lookback_window[1]+evaluation_window, :].index, columns=['return'], data=np.zeros(len(df_cleaned.iloc[lookback_window[1]:lookback_window[1]+evaluation_window, :].index)))\n",
    "\n",
    "    for ticker, weight in markowitz_weights.items(): \n",
    "\n",
    "    ##  each time we add :            the present value of the return + the weighted \"contribution\" of the stock 'ticker' times is weight in the portfolio\n",
    "        portfolio_returns['return'] = portfolio_returns['return'] + df_cleaned[ticker][lookback_window[1]:lookback_window[1]+evaluation_window]*weight\n",
    "\n",
    "    return portfolio_returns\n",
    "\n",
    "lookback_window = [0, 200]\n",
    "evaluation_window = 1\n",
    "beta = 0.95\n",
    "K = 4  # Number of fold for the cross validation\n",
    "eta = 0.1\n",
    "\n",
    "cov = cov_forecast(beta=beta, lookback_window=lookback_window, number_folds=K, historical_data=df_cleaned)\n",
    "ret = portfolio_returns(historical_data=df_cleaned, evaluation_window=evaluation_window, lookback_window=lookback_window, cov=cov, eta=eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyFolioC import PyFolio\n",
    "from PyFolioC import PyFolioC\n",
    "\n",
    "historical_data = df_cleaned\n",
    "number_of_repetitions = 10\n",
    "lookback_window = [0, 50]\n",
    "evaluation_window = 1\n",
    "number_of_clusters = 38\n",
    "clustering_method = 'SPONGE'\n",
    "sigma = 0.1\n",
    "eta = 0.1\n",
    "\n",
    "consolidated_W = PyFolioC(number_of_repetitions=number_of_repetitions, historical_data=df_cleaned, lookback_window=lookback_window, evaluation_window=evaluation_window, number_of_clusters=number_of_clusters, sigma=sigma, eta=eta, clustering_method=clustering_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x \n",
    "\n",
    "isinstance(x, int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcul_somme(beta):\n",
    "\n",
    "    T = len(consolidated_W.historical_data.columns)\n",
    "    \n",
    "    res = np.zeros((len(df_column[0]), len(df_column[0])))\n",
    "\n",
    "    res = (1 - beta) / (1 - beta**T) * np.sum([(beta**(T-(t+1))) * np.outer(consolidated_W.historical_data[ticker], consolidated_W.historical_data[ticker]) for t, ticker in enumerate(consolidated_W.historical_data.columns)])\n",
    "\n",
    "    return res\n",
    "\n",
    "beta = 0.5\n",
    "\n",
    "res = calcul_somme(beta=beta)\n",
    "res \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
