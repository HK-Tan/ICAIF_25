{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import process\n",
    "import numpy as np \n",
    "# Jerome path : r'C:\\Users\\33640\\OneDrive\\Documents\\GitHub\\Portfolio_clustering_project\\Data\\DataBase.csv'\n",
    "# Nail path : '/Users/khelifanail/Documents/GitHub/Portfolio_clustering_project/Data/DataBase.csv'\n",
    "df = pd.read_csv(r'/Users/khelifanail/Documents/GitHub/Portfolio_clustering_project/Data/DataBase.csv')\n",
    "\n",
    "df.set_index('ticker', inplace=True)\n",
    "\n",
    "df.columns = pd.to_datetime(df.columns.str[1:], format='%Y%m%d').strftime('%d/%m/%Y')\n",
    "\n",
    "df_cleaned = df.fillna(0) # Utilisez la méthode fillna(0) pour remplacer les NaN par 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after function definition on line 6 (2352418720.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[94], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    result = dict(zip(list(self.correlation_matrix.columns), self.apply_SPONGE())) ## composition\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 6\n"
     ]
    }
   ],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "lookback_window = [0, 50]\n",
    "number_of_clusters = 38\n",
    "\n",
    "def cluster_composition_and_centroid(self):\n",
    "## cluster composition and centroids\n",
    "\n",
    "result = dict(zip(list(self.correlation_matrix.columns), self.apply_SPONGE())) ## composition\n",
    "\n",
    "df_cleaned['Cluster'] = df_cleaned.index.map(result)\n",
    "centroid_returns = df_cleaned.groupby('Cluster').mean() ## centroids \n",
    "\n",
    "df_cleaned = df_cleaned.transpose()\n",
    "centroid_returns = centroid_returns.transpose()\n",
    "\n",
    "## constituent_weights\n",
    "centred_returns = df_cleaned.copy()\n",
    "sigma = 0.01\n",
    "\n",
    "constituent_weights = pd.DataFrame(index=['Weight'], columns=centred_returns.columns)\n",
    "total_weight = pd.DataFrame(index=['Total weight'], columns=[i for i in range(number_of_clusters)], data=np.zeros((1, number_of_clusters)))\n",
    "\n",
    "## we first compute the difference between the cluster centroid return and the cluster ticker return\n",
    "for ticker in centred_returns.columns:\n",
    "    centred_returns[ticker][:-1] = centred_returns[ticker][:-1] - centroid_returns[int(centred_returns[ticker]['Cluster'])]\n",
    "\n",
    "## we use this difference to compute the distance between each asset and its cluster centroid return \n",
    "for ticker in centred_returns.columns:\n",
    "    constituent_weights[ticker] = np.exp(sigma*((np.linalg.norm(centred_returns[ticker][:-1]))**2)/2)\n",
    "    total_weight[int(centred_returns[ticker]['Cluster'])]['Total weight'] += np.exp(sigma*((np.linalg.norm(centred_returns[ticker][:-1]))**2)/2)\n",
    "\n",
    "## we normalize the weights\n",
    "for ticker in centred_returns.columns:\n",
    "    constituent_weights[ticker] = constituent_weights[ticker]['Weight']/total_weight[int(centred_returns[ticker]['Cluster'])]['Total weight']\n",
    "\n",
    "## check whether the weights equal to 0 within each cluster: \n",
    "# constituent_weights[[ticker for ticker in centred_returns.columns if centred_returns[ticker]['Cluster']  == 1.0]].sum(axis=1)\n",
    "    \n",
    "## cluster returns \n",
    "    \n",
    "cluster_returns = pd.DataFrame(index=df_cleaned.index[:-1], columns=np.arange(number_of_clusters), data=np.zeros((df_cleaned.shape[0] - 1, number_of_clusters)))\n",
    "\n",
    "for ticker in df_cleaned.columns:\n",
    "    cluster_returns[int(df_cleaned[ticker]['Cluster'])] = cluster_returns[int(df_cleaned[ticker]['Cluster'])] + constituent_weights[ticker]['Weight'] * df_cleaned[ticker][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported type: <class 'numpy.float64'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/q2/wg5gyfhj2r9cd97zfmckktvw0000gn/T/ipykernel_17295/1084650963.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mcorr_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorrelation_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlookback_window\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlookback_window\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_cleaned\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_cleaned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mcluster_comp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_composition_and_centroid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_cleaned\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_cleaned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrelation_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorr_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumber_of_clusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookback_window\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlookback_window\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclustering_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclustering_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mconstituent_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstituent_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_cleaned\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_cleaned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster_composition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcluster_comp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookback_window\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlookback_window\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mcluster_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconstituent_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstituent_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_cleaned\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_cleaned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookback_window\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlookback_window\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mmarkowitz_weights_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmarkowitz_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster_return_res\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcluster_return\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstituent_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstituent_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_cleaned\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_cleaned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookback_window\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlookback_window\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluation_window\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluation_window\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/GitHub/Portfolio_clustering_project/Code/process.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(cluster_return_res, constituent_weights, df_cleaned, lookback_window, evaluation_window, eta)\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[0;31m## on construit le vecteur d'expected return du cluster (252 jours de trading par an, on passe de rendements journaliers à rendements annualisés)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[0mcluster_target_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcluster_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconstituent_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstituent_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_cleaned\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_cleaned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookback_window\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlookback_window\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookback_window\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mevaluation_window\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m     \u001b[0mexpected_returns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnoised_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcluster_target_return\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0mef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEfficientFrontier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_returns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpected_returns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcov_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_bounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/Portfolio_clustering_project/Code/process.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(y, eta)\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon_std_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnoise\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0mcorrelation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;31m# Adjust the standard deviation of the noise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0mepsilon_std_dev\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m0.0005\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, other, method, min_periods)\u001b[0m\n\u001b[1;32m   2955\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0ms2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2956\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0ms1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2957\u001b[0m         \u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2958\u001b[0m         \"\"\"  # noqa: E501\n\u001b[0;32m-> 2959\u001b[0;31m         \u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"inner\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2960\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2961\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, other, join, axis, level, copy, fill_value, method, limit, fill_axis, broadcast_axis)\u001b[0m\n\u001b[1;32m  10449\u001b[0m                 \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10450\u001b[0m                 \u001b[0mfill_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_axis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10451\u001b[0m             )\n\u001b[1;32m  10452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10453\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"unsupported type: {type(other)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10455\u001b[0m         \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNDFrameT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_right\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10456\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported type: <class 'numpy.float64'>"
     ]
    }
   ],
   "source": [
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "import process\n",
    "from PyFolioCC import PyFolioCC \n",
    "\n",
    "historical_data = df_cleaned\n",
    "lookback_window = [0, 50]\n",
    "evaluation_window = 1\n",
    "number_of_clusters = 38\n",
    "clustering_method = 'SPONGE'\n",
    "sigma = 0.1\n",
    "eta = 0.1\n",
    "\n",
    "corr_matrix = process.correlation_matrix(lookback_window=lookback_window, df_cleaned=df_cleaned)\n",
    "cluster_comp = process.cluster_composition_and_centroid(df_cleaned=df_cleaned, correlation_matrix=corr_matrix, number_of_clusters=number_of_clusters, lookback_window=lookback_window, clustering_method=clustering_method)\n",
    "constituent_weights = process.constituent_weights(df_cleaned=df_cleaned, cluster_composition=cluster_comp, sigma=sigma, lookback_window=lookback_window)\n",
    "cluster_return = process.cluster_return(constituent_weights=constituent_weights, df_cleaned=df_cleaned, lookback_window=lookback_window)\n",
    "markowitz_weights_res = process.markowitz_weights(cluster_return_res=cluster_return, constituent_weights=constituent_weights, df_cleaned=df_cleaned, lookback_window=lookback_window, evaluation_window=evaluation_window, eta=eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster 1    -0.005723\n",
       "cluster 2    -0.001280\n",
       "cluster 3    -0.001702\n",
       "cluster 4     0.000007\n",
       "cluster 5    -0.004083\n",
       "cluster 6     0.002737\n",
       "cluster 7    -0.000691\n",
       "cluster 8    -0.000855\n",
       "cluster 9    -0.004311\n",
       "cluster 10    0.001726\n",
       "cluster 11   -0.000147\n",
       "cluster 12    0.001738\n",
       "cluster 13   -0.000769\n",
       "cluster 14   -0.003506\n",
       "cluster 15   -0.000850\n",
       "cluster 16   -0.004075\n",
       "cluster 17   -0.000703\n",
       "cluster 18   -0.000968\n",
       "cluster 19   -0.001793\n",
       "cluster 20    0.001216\n",
       "cluster 21   -0.000608\n",
       "cluster 22   -0.000837\n",
       "cluster 23   -0.001091\n",
       "cluster 24   -0.003312\n",
       "cluster 25   -0.000491\n",
       "cluster 26   -0.000896\n",
       "cluster 27   -0.000612\n",
       "cluster 28   -0.002951\n",
       "cluster 29    0.000846\n",
       "cluster 30   -0.002832\n",
       "cluster 31   -0.002775\n",
       "cluster 32    0.001943\n",
       "cluster 33   -0.004813\n",
       "cluster 34   -0.005190\n",
       "cluster 35    0.000575\n",
       "cluster 36   -0.002211\n",
       "cluster 37   -0.001629\n",
       "cluster 38    0.000319\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_return.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "03/01/2000   -0.013042\n",
       "04/01/2000    0.010043\n",
       "05/01/2000    0.047628\n",
       "06/01/2000   -0.011713\n",
       "07/01/2000   -0.016118\n",
       "10/01/2000   -0.032073\n",
       "11/01/2000    0.022608\n",
       "12/01/2000   -0.005249\n",
       "13/01/2000   -0.018210\n",
       "14/01/2000   -0.020109\n",
       "18/01/2000   -0.033100\n",
       "19/01/2000    0.001601\n",
       "20/01/2000   -0.028502\n",
       "21/01/2000    0.015038\n",
       "24/01/2000   -0.034299\n",
       "25/01/2000   -0.015438\n",
       "26/01/2000   -0.015666\n",
       "27/01/2000   -0.021053\n",
       "28/01/2000   -0.024868\n",
       "31/01/2000   -0.002687\n",
       "01/02/2000    0.019248\n",
       "02/02/2000    0.039321\n",
       "03/02/2000   -0.031505\n",
       "04/02/2000   -0.027974\n",
       "07/02/2000   -0.038691\n",
       "08/02/2000   -0.045399\n",
       "09/02/2000   -0.019158\n",
       "10/02/2000    0.007663\n",
       "11/02/2000    0.019581\n",
       "14/02/2000    0.053299\n",
       "15/02/2000    0.028316\n",
       "16/02/2000    0.000848\n",
       "17/02/2000    0.038928\n",
       "18/02/2000   -0.018107\n",
       "22/02/2000   -0.028889\n",
       "23/02/2000   -0.026021\n",
       "24/02/2000   -0.025676\n",
       "25/02/2000    0.008047\n",
       "28/02/2000    0.020436\n",
       "29/02/2000   -0.035846\n",
       "01/03/2000    0.018997\n",
       "02/03/2000   -0.032216\n",
       "03/03/2000    0.023268\n",
       "06/03/2000   -0.025879\n",
       "07/03/2000   -0.023777\n",
       "08/03/2000    0.029179\n",
       "09/03/2000    0.010209\n",
       "10/03/2000   -0.000932\n",
       "13/03/2000    0.019472\n",
       "14/03/2000   -0.068040\n",
       "Name: AA, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.transpose()['AA'][lookback_window[0]:lookback_window[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_returns = pd.DataFrame(index = df_cleaned.columns[lookback_window[0]:lookback_window[1]], columns= [f'cluster {i}' for i in range(1, number_of_clusters + 1)], data = np.zeros((len(df_cleaned.columns[lookback_window[0]:lookback_window[1]]), len(constituent_weights) + 1)))\n",
    "\n",
    "for cluster in constituent_weights.keys():\n",
    "    for ticker, weight in constituent_weights[cluster].items():\n",
    "        cluster_returns[cluster] = cluster_returns[cluster] + df_cleaned.transpose()[ticker][lookback_window[0]:lookback_window[1]]*weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(695, 695) 37 37 37 37 692\n"
     ]
    }
   ],
   "source": [
    "corr_matrix = process.correlation_matrix(lookback_window=lookback_window, df_cleaned=df_cleaned)\n",
    "cluster_comp = process.cluster_composition_and_centroid(df_cleaned=df_cleaned, correlation_matrix=corr_matrix, number_of_clusters=number_of_clusters, lookback_window=lookback_window, clustering_method=clustering_method)\n",
    "constituent_weights = process.constituent_weights(df_cleaned=df_cleaned, cluster_composition=cluster_comp, sigma=sigma, lookback_window=lookback_window)\n",
    "cluster_return = process.cluster_return(constituent_weights=constituent_weights, df_cleaned=df_cleaned, lookback_window=lookback_window)\n",
    "markowitz_weights_res = process.markowitz_weights(cluster_return_res=cluster_return, constituent_weights=constituent_weights, df_cleaned=df_cleaned, lookback_window=lookback_window, evaluation_window=evaluation_window, eta=eta)\n",
    "final_weights = process.final_weights(markowitz_weights=markowitz_weights_res, constituent_weights=constituent_weights)\n",
    "print(corr_matrix.shape, len(cluster_comp), len(constituent_weights), len(cluster_return), len(markowitz_weights_res), len(final_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVA 3.921716041425027e-05\n",
      "BKH 0.110883916406304\n",
      "BXS 0.2035512296849513\n",
      "DRQ 0.04082643926897566\n",
      "INCY 1.0230500389790201e-11\n",
      "LNT 0.1654632187161882\n",
      "MTZ 0.14365464588183466\n",
      "NI 0.05214005001251528\n",
      "OKE 0.2394986472578898\n",
      "PKI 0.01829458705579904\n",
      "RMD 0.02564804854489745\n"
     ]
    }
   ],
   "source": [
    "cluster_returns = pd.DataFrame(index = [f'cluster {i}' for i in range(1, len(constituent_weights) + 1)], columns = df_cleaned.columns[lookback_window[0]:lookback_window[1]])\n",
    "for keys, value in constituent_weights['cluster 1'].items():\n",
    "    print(keys, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
