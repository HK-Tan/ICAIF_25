{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\33640\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "c:\\Users\\33640\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n",
      "C:\\Users\\33640\\AppData\\Local\\Temp/ipykernel_33544/396982650.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import process\n",
    "import numpy as np \n",
    "# Jerome path : r'C:\\Users\\33640\\OneDrive\\Documents\\GitHub\\Portfolio_clustering_project\\Data\\DataBase.csv'\n",
    "# Nail path : '/Users/khelifanail/Documents/GitHub/Portfolio_clustering_project/Data/DataBase.csv'\n",
    "df = pd.read_csv(r'C:\\Users\\33640\\OneDrive\\Documents\\GitHub\\Portfolio_clustering_project\\Data\\DataBase.csv')\n",
    "\n",
    "df.set_index('ticker', inplace=True)\n",
    "\n",
    "df.columns = pd.to_datetime(df.columns.str[1:], format='%Y%m%d').strftime('%d/%m/%Y')\n",
    "\n",
    "df_cleaned = df.fillna(0) # Utilisez la m√©thode fillna(0) pour remplacer les NaN par 0\n",
    "\n",
    "df_cleaned = df_cleaned.transpose() ## WE WANT COLUMNS TO BE VECTOR OF RETURN FOR A GIVEN TICKER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 0.95\n",
    "K = 4  # Number of fold for the cross validation\n",
    "N = 695  # Number of assets\n",
    "Ik_length = 50  # Number of days in each fold for the cross validation\n",
    "\n",
    "# Initialize epsilon as a zero array with N elements\n",
    "epsilon = np.zeros(N)\n",
    "\n",
    "\n",
    "for k in range(K):\n",
    "    # Calculate EWA matrix \n",
    "    weighted_matrices = [(beta**(Ik_length-t)) * np.outer(df_cleaned.iloc[t + Ik_length*k], df_cleaned.iloc[t + Ik_length*k]) for t in range(Ik_length)]\n",
    "    summed_weighted_matrices = np.sum(weighted_matrices, axis=0)\n",
    "    E_matrix = (1 - beta) / (1 - beta**Ik_length) * summed_weighted_matrices\n",
    "    \n",
    "    # Calculate eigenvectors for the E matrix\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(E_matrix)\n",
    "\n",
    "    # Calculate epsilon terms for each eigenvector\n",
    "    for i in range(N):\n",
    "        ui = eigenvectors[:, i]\n",
    "        # For each day in the Ik segment, project the data onto the eigenvector and square it\n",
    "        epsilon_i_sum = np.sum([(np.dot(ui, df_cleaned.iloc[t + Ik_length*k])**2) for t in range(Ik_length)])\n",
    "        # Accumulate the results in epsilon\n",
    "        epsilon[i] += epsilon_i_sum.real / Ik_length\n",
    "\n",
    "# Average epsilon over K segments\n",
    "epsilon /= K\n",
    "\n",
    "# Now, we calculate the forecasts using the last set of eigenvectors\n",
    "Forecasts = np.sum([epsilon[i] * np.outer(eigenvectors[:, i], eigenvectors[:, i]) for i in range(N)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyFolioC import PyFolio\n",
    "from PyFolioC import PyFolioC\n",
    "\n",
    "historical_data = df_cleaned\n",
    "number_of_repetitions = 10\n",
    "lookback_window = [0, 50]\n",
    "evaluation_window = 1\n",
    "number_of_clusters = 38\n",
    "clustering_method = 'SPONGE'\n",
    "sigma = 0.1\n",
    "eta = 0.1\n",
    "\n",
    "consolidated_W = PyFolioC(number_of_repetitions=number_of_repetitions, historical_data=df_cleaned, lookback_window=lookback_window, evaluation_window=evaluation_window, number_of_clusters=number_of_clusters, sigma=sigma, eta=eta, clustering_method=clustering_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0044931623282323\n",
      "step 1\n",
      "1.0166687281847513\n",
      "step 2\n",
      "1.0195083623502044\n",
      "step 3\n",
      "1.0203762217597587\n",
      "step 4\n",
      "1.0256214503165464\n",
      "step 5\n",
      "1.0278326613983257\n",
      "step 6\n",
      "1.030928249800027\n",
      "step 7\n",
      "1.0304429207078931\n",
      "step 8\n",
      "1.0314772312816862\n",
      "step 9\n",
      "1.0320651616089225\n",
      "step 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(              return\n",
       " 15/03/2000  0.004493\n",
       " 16/03/2000  0.012121\n",
       " 17/03/2000  0.002793\n",
       " 20/03/2000  0.000851\n",
       " 21/03/2000  0.005140\n",
       " 22/03/2000  0.002156\n",
       " 23/03/2000  0.003012\n",
       " 24/03/2000 -0.000471\n",
       " 27/03/2000  0.001004\n",
       " 28/03/2000  0.000570,\n",
       " array([0.  , 0.02, 0.02, 0.02, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03]),\n",
       " [1,\n",
       "  1.0044931623282323,\n",
       "  1.0166687281847513,\n",
       "  1.0195083623502044,\n",
       "  1.0203762217597587,\n",
       "  1.0256214503165464,\n",
       "  1.0278326613983257,\n",
       "  1.030928249800027,\n",
       "  1.0304429207078931,\n",
       "  1.0314772312816862,\n",
       "  1.0320651616089225],\n",
       " array([ 0.  ,  0.01,  0.  ,  0.  ,  0.01,  0.  ,  0.  , -0.  ,  0.  ,\n",
       "         0.  ]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consolidated_W.sliding_window(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcul_somme(beta):\n",
    "\n",
    "    T = len(consolidated_W.historical_data.columns)\n",
    "    \n",
    "    res = np.zeros((len(df_column[0]), len(df_column[0])))\n",
    "\n",
    "    res = (1 - beta) / (1 - beta**T) * np.sum([(beta**(T-(t+1))) * np.outer(consolidated_W.historical_data[ticker], consolidated_W.historical_data[ticker]) for t, ticker in enumerate(consolidated_W.historical_data.columns)])\n",
    "\n",
    "    return res\n",
    "\n",
    "beta = 0.5\n",
    "\n",
    "res = calcul_somme(beta=beta)\n",
    "res \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
