{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import process\n",
    "import numpy as np \n",
    "# Jerome path : r'C:\\Users\\33640\\OneDrive\\Documents\\GitHub\\Portfolio_clustering_project\\Data\\DataBase.csv'\n",
    "# Nail path : '/Users/khelifanail/Documents/GitHub/Portfolio_clustering_project/Data/DataBase.csv'\n",
    "df = pd.read_csv(r'/Users/khelifanail/Documents/GitHub/Portfolio_clustering_project/Data/DataBase.csv')\n",
    "\n",
    "df.set_index('ticker', inplace=True)\n",
    "\n",
    "df.columns = pd.to_datetime(df.columns.str[1:], format='%Y%m%d').strftime('%d/%m/%Y')\n",
    "\n",
    "df_cleaned = df.fillna(0) # Utilisez la m√©thode fillna(0) pour remplacer les NaN par 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after function definition on line 6 (2352418720.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[94], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    result = dict(zip(list(self.correlation_matrix.columns), self.apply_SPONGE())) ## composition\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 6\n"
     ]
    }
   ],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "lookback_window = [0, 50]\n",
    "number_of_clusters = 38\n",
    "\n",
    "def cluster_composition_and_centroid(self):\n",
    "## cluster composition and centroids\n",
    "\n",
    "result = dict(zip(list(self.correlation_matrix.columns), self.apply_SPONGE())) ## composition\n",
    "\n",
    "df_cleaned['Cluster'] = df_cleaned.index.map(result)\n",
    "centroid_returns = df_cleaned.groupby('Cluster').mean() ## centroids \n",
    "\n",
    "df_cleaned = df_cleaned.transpose()\n",
    "centroid_returns = centroid_returns.transpose()\n",
    "\n",
    "## constituent_weights\n",
    "centred_returns = df_cleaned.copy()\n",
    "sigma = 0.01\n",
    "\n",
    "constituent_weights = pd.DataFrame(index=['Weight'], columns=centred_returns.columns)\n",
    "total_weight = pd.DataFrame(index=['Total weight'], columns=[i for i in range(number_of_clusters)], data=np.zeros((1, number_of_clusters)))\n",
    "\n",
    "## we first compute the difference between the cluster centroid return and the cluster ticker return\n",
    "for ticker in centred_returns.columns:\n",
    "    centred_returns[ticker][:-1] = centred_returns[ticker][:-1] - centroid_returns[int(centred_returns[ticker]['Cluster'])]\n",
    "\n",
    "## we use this difference to compute the distance between each asset and its cluster centroid return \n",
    "for ticker in centred_returns.columns:\n",
    "    constituent_weights[ticker] = np.exp(sigma*((np.linalg.norm(centred_returns[ticker][:-1]))**2)/2)\n",
    "    total_weight[int(centred_returns[ticker]['Cluster'])]['Total weight'] += np.exp(sigma*((np.linalg.norm(centred_returns[ticker][:-1]))**2)/2)\n",
    "\n",
    "## we normalize the weights\n",
    "for ticker in centred_returns.columns:\n",
    "    constituent_weights[ticker] = constituent_weights[ticker]['Weight']/total_weight[int(centred_returns[ticker]['Cluster'])]['Total weight']\n",
    "\n",
    "## check whether the weights equal to 0 within each cluster: \n",
    "# constituent_weights[[ticker for ticker in centred_returns.columns if centred_returns[ticker]['Cluster']  == 1.0]].sum(axis=1)\n",
    "    \n",
    "## cluster returns \n",
    "    \n",
    "cluster_returns = pd.DataFrame(index=df_cleaned.index[:-1], columns=np.arange(number_of_clusters), data=np.zeros((df_cleaned.shape[0] - 1, number_of_clusters)))\n",
    "\n",
    "for ticker in df_cleaned.columns:\n",
    "    cluster_returns[int(df_cleaned[ticker]['Cluster'])] = cluster_returns[int(df_cleaned[ticker]['Cluster'])] + constituent_weights[ticker]['Weight'] * df_cleaned[ticker][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "import process\n",
    "from PyFolioCC import PyFolioCC \n",
    "\n",
    "historical_data = df_cleaned\n",
    "lookback_window = [0, 50]\n",
    "evaluation_window = 1\n",
    "number_of_clusters = 38\n",
    "clustering_method = 'SPONGE'\n",
    "sigma = 0.01\n",
    "eta = 0.1\n",
    "\n",
    "corr_matrix = process.correlation_matrix(lookback_window=lookback_window, df_cleaned=df_cleaned)\n",
    "cluster_comp = process.cluster_composition_and_centroid(df_cleaned=df_cleaned, correlation_matrix=corr_matrix, number_of_clusters=number_of_clusters, lookback_window=lookback_window, clustering_method=clustering_method)\n",
    "constituent_weights = process.constituent_weights(df_cleaned=df_cleaned, cluster_composition=cluster_comp, sigma=sigma, lookback_window=lookback_window)\n",
    "cluster_return = process.cluster_return(constituent_weights=constituent_weights, df_cleaned=df_cleaned, lookback_window=lookback_window)\n",
    "markowitz_weights_res = process.markowitz_weights(cluster_return_res=cluster_return, constituent_weights=constituent_weights, df_cleaned=df_cleaned, lookback_window=lookback_window, evaluation_window=evaluation_window, eta=eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio = PyFolioCC(historical_data=historical_data, lookback_window=lookback_window, evaluation_window=evaluation_window, number_of_clusters=number_of_clusters, sigma=sigma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "03/01/2000   -0.000048\n",
       "04/01/2000   -0.000022\n",
       "05/01/2000   -0.000056\n",
       "06/01/2000    0.000067\n",
       "07/01/2000   -0.000050\n",
       "                ...   \n",
       "24/12/2020   -0.000034\n",
       "28/12/2020   -0.000006\n",
       "29/12/2020   -0.000091\n",
       "30/12/2020    0.000048\n",
       "31/12/2020   -0.000044\n",
       "Name: 0, Length: 5279, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns = portfolio.cluster_returns\n",
    "returns \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
