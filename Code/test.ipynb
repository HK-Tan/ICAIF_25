{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import process\n",
    "import numpy as np \n",
    "# Jerome path : r'C:\\Users\\33640\\OneDrive\\Documents\\GitHub\\Portfolio_clustering_project\\Data\\DataBase.csv'\n",
    "# Nail path : '/Users/khelifanail/Documents/GitHub/Portfolio_clustering_project/Data/DataBase.csv'\n",
    "df = pd.read_csv(r'/Users/khelifanail/Documents/GitHub/Portfolio_clustering_project/Data/DataBase.csv')\n",
    "\n",
    "df.set_index('ticker', inplace=True)\n",
    "\n",
    "df.columns = pd.to_datetime(df.columns.str[1:], format='%Y%m%d').strftime('%d/%m/%Y')\n",
    "\n",
    "df_cleaned = df.fillna(0) # Utilisez la mÃ©thode fillna(0) pour remplacer les NaN par 0\n",
    "\n",
    "df_cleaned = df_cleaned.transpose() ## WE WANT COLUMNS TO BE VECTOR OF RETURN FOR A GIVEN TICKER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "import process\n",
    "from PyFolioCC import PyFolioCC \n",
    "\n",
    "historical_data = df_cleaned\n",
    "number_of_repetitions = 10\n",
    "lookback_window = [0, 50]\n",
    "evaluation_window = 1\n",
    "number_of_clusters = 38\n",
    "clustering_method = 'SPONGE'\n",
    "sigma = 0.1\n",
    "eta = 0.1\n",
    "\n",
    "corr_matrix = process.correlation_matrix(lookback_window=lookback_window, df_cleaned=df_cleaned)\n",
    "cluster_comp = process.cluster_composition_and_centroid(df_cleaned=df_cleaned, correlation_matrix=corr_matrix, number_of_clusters=number_of_clusters, lookback_window=lookback_window, clustering_method=clustering_method)\n",
    "constituent_weights = process.constituent_weights(df_cleaned=df_cleaned, cluster_composition=cluster_comp, sigma=sigma, lookback_window=lookback_window)\n",
    "cluster_return_res = process.cluster_return(constituent_weights=constituent_weights, df_cleaned=df_cleaned, lookback_window=lookback_window)\n",
    "markowitz_weights_res = process.markowitz_weights(cluster_return_res=cluster_return_res, constituent_weights=constituent_weights, df_cleaned=df_cleaned, lookback_window=lookback_window, evaluation_window=evaluation_window, eta=eta)\n",
    "final_weights = process.final_weights(markowitz_weights=markowitz_weights_res, constituent_weights=constituent_weights)\n",
    "W = process.training_phase(lookback_window=lookback_window, df_cleaned=df_cleaned, number_of_clusters=number_of_clusters, sigma=sigma, evaluation_window=evaluation_window, eta=eta, clustering_method=clustering_method)\n",
    "\n",
    "consolidated_W = process.consolidated_W(number_of_repetitions=number_of_repetitions, lookback_window=lookback_window, df_cleaned=df_cleaned, number_of_clusters=number_of_clusters, sigma=sigma, evaluation_window=evaluation_window, eta=eta, clustering_method=clustering_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "03/01/2000   -0.014660\n",
       "04/01/2000   -0.039051\n",
       "05/01/2000   -0.048625\n",
       "06/01/2000   -0.011655\n",
       "07/01/2000    0.011655\n",
       "                ...   \n",
       "24/12/2020   -0.009528\n",
       "28/12/2020    0.010277\n",
       "29/12/2020   -0.014516\n",
       "30/12/2020   -0.000574\n",
       "31/12/2020    0.012323\n",
       "Name: AVT, Length: 5279, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned['AVT']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'AVT'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:153\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:182\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'AVT'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/khelifanail/Documents/GitHub/Portfolio_clustering_project/Code/test.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/khelifanail/Documents/GitHub/Portfolio_clustering_project/Code/test.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m portfolio_returns \u001b[39m=\u001b[39m process\u001b[39m.\u001b[39;49mportfolio_returns(evaluation_window\u001b[39m=\u001b[39;49mevaluation_window, df_cleaned\u001b[39m=\u001b[39;49mdf_cleaned, lookback_window\u001b[39m=\u001b[39;49mlookback_window, consolidated_W\u001b[39m=\u001b[39;49mconsolidated_W)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/khelifanail/Documents/GitHub/Portfolio_clustering_project/Code/test.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m portfolio_returns\n",
      "File \u001b[0;32m~/Documents/GitHub/Portfolio_clustering_project/Code/process.py:623\u001b[0m, in \u001b[0;36mportfolio_returns\u001b[0;34m(evaluation_window, df_cleaned, lookback_window, consolidated_W)\u001b[0m\n\u001b[1;32m    618\u001b[0m portfolio_returns \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(index\u001b[39m=\u001b[39mdf_cleaned\u001b[39m.\u001b[39miloc[lookback_window[\u001b[39m1\u001b[39m]:lookback_window[\u001b[39m1\u001b[39m]\u001b[39m+\u001b[39mevaluation_window, :]\u001b[39m.\u001b[39mindex, columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mreturn\u001b[39m\u001b[39m'\u001b[39m], data\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mzeros(\u001b[39mlen\u001b[39m(df_cleaned\u001b[39m.\u001b[39miloc[lookback_window[\u001b[39m1\u001b[39m]:lookback_window[\u001b[39m1\u001b[39m]\u001b[39m+\u001b[39mevaluation_window, :]\u001b[39m.\u001b[39mindex)))\n\u001b[1;32m    620\u001b[0m \u001b[39mfor\u001b[39;00m ticker \u001b[39min\u001b[39;00m consolidated_W\u001b[39m.\u001b[39mcolumns: \n\u001b[1;32m    621\u001b[0m \n\u001b[1;32m    622\u001b[0m \u001b[39m##  each time we add :            the present value of the return + the weighted \"contribution\" of the stock 'ticker' times is weight in the portfolio\u001b[39;00m\n\u001b[0;32m--> 623\u001b[0m     portfolio_returns[\u001b[39m'\u001b[39m\u001b[39mreturn\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m portfolio_returns[\u001b[39m'\u001b[39m\u001b[39mreturn\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m df_cleaned\u001b[39m.\u001b[39;49mloc[ticker][lookback_window[\u001b[39m1\u001b[39m]:lookback_window[\u001b[39m1\u001b[39m]\u001b[39m+\u001b[39mevaluation_window]\u001b[39m*\u001b[39mconsolidated_W[ticker][\u001b[39m'\u001b[39m\u001b[39mweight\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    625\u001b[0m \u001b[39mreturn\u001b[39;00m portfolio_returns\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/indexing.py:1192\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1190\u001b[0m maybe_callable \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[1;32m   1191\u001b[0m maybe_callable \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[0;32m-> 1192\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_axis(maybe_callable, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/indexing.py:1432\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1430\u001b[0m \u001b[39m# fall thru to straight lookup\u001b[39;00m\n\u001b[1;32m   1431\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m-> 1432\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_label(key, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/indexing.py:1382\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m   1380\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_label\u001b[39m(\u001b[39mself\u001b[39m, label, axis: AxisInt):\n\u001b[1;32m   1381\u001b[0m     \u001b[39m# GH#5567 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[0;32m-> 1382\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49mxs(label, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/generic.py:4295\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   4293\u001b[0m             new_index \u001b[39m=\u001b[39m index[loc]\n\u001b[1;32m   4294\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 4295\u001b[0m     loc \u001b[39m=\u001b[39m index\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   4297\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(loc, np\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m   4298\u001b[0m         \u001b[39mif\u001b[39;00m loc\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mbool_:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/indexes/base.py:3809\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[1;32m   3805\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m   3806\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[1;32m   3807\u001b[0m     ):\n\u001b[1;32m   3808\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3809\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3811\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3812\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3814\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'AVT'"
     ]
    }
   ],
   "source": [
    "portfolio_returns = process.portfolio_returns(evaluation_window=evaluation_window, df_cleaned=df_cleaned, lookback_window=lookback_window, consolidated_W=consolidated_W)\n",
    "portfolio_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(695, 695) 37 37 37 37 692\n"
     ]
    }
   ],
   "source": [
    "corr_matrix = process.correlation_matrix(lookback_window=lookback_window, df_cleaned=df_cleaned)\n",
    "cluster_comp = process.cluster_composition_and_centroid(df_cleaned=df_cleaned, correlation_matrix=corr_matrix, number_of_clusters=number_of_clusters, lookback_window=lookback_window, clustering_method=clustering_method)\n",
    "constituent_weights = process.constituent_weights(df_cleaned=df_cleaned, cluster_composition=cluster_comp, sigma=sigma, lookback_window=lookback_window)\n",
    "cluster_return = process.cluster_return(constituent_weights=constituent_weights, df_cleaned=df_cleaned, lookback_window=lookback_window)\n",
    "markowitz_weights_res = process.markowitz_weights(cluster_return_res=cluster_return, constituent_weights=constituent_weights, df_cleaned=df_cleaned, lookback_window=lookback_window, evaluation_window=evaluation_window, eta=eta)\n",
    "final_weights = process.final_weights(markowitz_weights=markowitz_weights_res, constituent_weights=constituent_weights)\n",
    "print(corr_matrix.shape, len(cluster_comp), len(constituent_weights), len(cluster_return), len(markowitz_weights_res), len(final_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVA 3.921716041425027e-05\n",
      "BKH 0.110883916406304\n",
      "BXS 0.2035512296849513\n",
      "DRQ 0.04082643926897566\n",
      "INCY 1.0230500389790201e-11\n",
      "LNT 0.1654632187161882\n",
      "MTZ 0.14365464588183466\n",
      "NI 0.05214005001251528\n",
      "OKE 0.2394986472578898\n",
      "PKI 0.01829458705579904\n",
      "RMD 0.02564804854489745\n"
     ]
    }
   ],
   "source": [
    "cluster_returns = pd.DataFrame(index = [f'cluster {i}' for i in range(1, len(constituent_weights) + 1)], columns = df_cleaned.columns[lookback_window[0]:lookback_window[1]])\n",
    "for keys, value in constituent_weights['cluster 1'].items():\n",
    "    print(keys, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
