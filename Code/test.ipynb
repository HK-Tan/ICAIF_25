{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import process\n",
    "import numpy as np \n",
    "# Jerome path : r'C:\\Users\\33640\\OneDrive\\Documents\\GitHub\\Portfolio_clustering_project\\Data\\DataBase.csv'\n",
    "# Nail path : '/Users/khelifanail/Documents/GitHub/Portfolio_clustering_project/Data/DataBase.csv'\n",
    "df = pd.read_csv(r'/Users/khelifanail/Documents/GitHub/Portfolio_clustering_project/Data/DataBase.csv')\n",
    "\n",
    "df.set_index('ticker', inplace=True)\n",
    "\n",
    "df.columns = pd.to_datetime(df.columns.str[1:], format='%Y%m%d').strftime('%d/%m/%Y')\n",
    "\n",
    "df_cleaned = df.fillna(0) # Utilisez la m√©thode fillna(0) pour remplacer les NaN par 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after function definition on line 6 (2352418720.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[94], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    result = dict(zip(list(self.correlation_matrix.columns), self.apply_SPONGE())) ## composition\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 6\n"
     ]
    }
   ],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "lookback_window = [0, 50]\n",
    "number_of_clusters = 38\n",
    "\n",
    "def cluster_composition_and_centroid(self):\n",
    "## cluster composition and centroids\n",
    "\n",
    "result = dict(zip(list(self.correlation_matrix.columns), self.apply_SPONGE())) ## composition\n",
    "\n",
    "df_cleaned['Cluster'] = df_cleaned.index.map(result)\n",
    "centroid_returns = df_cleaned.groupby('Cluster').mean() ## centroids \n",
    "\n",
    "df_cleaned = df_cleaned.transpose()\n",
    "centroid_returns = centroid_returns.transpose()\n",
    "\n",
    "## constituent_weights\n",
    "centred_returns = df_cleaned.copy()\n",
    "sigma = 0.01\n",
    "\n",
    "constituent_weights = pd.DataFrame(index=['Weight'], columns=centred_returns.columns)\n",
    "total_weight = pd.DataFrame(index=['Total weight'], columns=[i for i in range(number_of_clusters)], data=np.zeros((1, number_of_clusters)))\n",
    "\n",
    "## we first compute the difference between the cluster centroid return and the cluster ticker return\n",
    "for ticker in centred_returns.columns:\n",
    "    centred_returns[ticker][:-1] = centred_returns[ticker][:-1] - centroid_returns[int(centred_returns[ticker]['Cluster'])]\n",
    "\n",
    "## we use this difference to compute the distance between each asset and its cluster centroid return \n",
    "for ticker in centred_returns.columns:\n",
    "    constituent_weights[ticker] = np.exp(sigma*((np.linalg.norm(centred_returns[ticker][:-1]))**2)/2)\n",
    "    total_weight[int(centred_returns[ticker]['Cluster'])]['Total weight'] += np.exp(sigma*((np.linalg.norm(centred_returns[ticker][:-1]))**2)/2)\n",
    "\n",
    "## we normalize the weights\n",
    "for ticker in centred_returns.columns:\n",
    "    constituent_weights[ticker] = constituent_weights[ticker]['Weight']/total_weight[int(centred_returns[ticker]['Cluster'])]['Total weight']\n",
    "\n",
    "## check whether the weights equal to 0 within each cluster: \n",
    "# constituent_weights[[ticker for ticker in centred_returns.columns if centred_returns[ticker]['Cluster']  == 1.0]].sum(axis=1)\n",
    "    \n",
    "## cluster returns \n",
    "    \n",
    "cluster_returns = pd.DataFrame(index=df_cleaned.index[:-1], columns=np.arange(number_of_clusters), data=np.zeros((df_cleaned.shape[0] - 1, number_of_clusters)))\n",
    "\n",
    "for ticker in df_cleaned.columns:\n",
    "    cluster_returns[int(df_cleaned[ticker]['Cluster'])] = cluster_returns[int(df_cleaned[ticker]['Cluster'])] + constituent_weights[ticker]['Weight'] * df_cleaned[ticker][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PyFolioCC' object has no attribute 'corlation_matrix'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/khelifanail/Documents/GitHub/Portfolio_clustering_project/Code/test.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/khelifanail/Documents/GitHub/Portfolio_clustering_project/Code/test.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m clustering_method \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mSPONGE\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/khelifanail/Documents/GitHub/Portfolio_clustering_project/Code/test.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m sigma \u001b[39m=\u001b[39m \u001b[39m0.01\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/khelifanail/Documents/GitHub/Portfolio_clustering_project/Code/test.ipynb#W4sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m portfolio \u001b[39m=\u001b[39m PyFolioCC(historical_data\u001b[39m=\u001b[39;49mhistorical_data, lookback_window\u001b[39m=\u001b[39;49mlookback_window, evaluation_window\u001b[39m=\u001b[39;49mevaluation_window, number_of_clusters\u001b[39m=\u001b[39;49mnumber_of_clusters, sigma\u001b[39m=\u001b[39;49msigma)\n",
      "File \u001b[0;32m~/Documents/GitHub/Portfolio_clustering_project/Code/PyFolioCC.py:69\u001b[0m, in \u001b[0;36mPyFolioCC.__init__\u001b[0;34m(self, historical_data, lookback_window, evaluation_window, number_of_clusters, sigma, clustering_method)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcorrelation_matrix \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcorr_matrix()\n\u001b[1;32m     68\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msigma \u001b[39m=\u001b[39m sigma\n\u001b[0;32m---> 69\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcluster_returns \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcluster_returns(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msigma)\n",
      "File \u001b[0;32m~/Documents/GitHub/Portfolio_clustering_project/Code/PyFolioCC.py:265\u001b[0m, in \u001b[0;36mPyFolioCC.cluster_returns\u001b[0;34m(self, sigma)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[39m\u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[39m----------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[39mGENERAL IDEA : \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[39m----------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[39m## cluster composition and centroids\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcorrelation_matrix\u001b[39m.\u001b[39mcolumns), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_SPONGE())) \u001b[39m## composition\u001b[39;00m\n\u001b[1;32m    267\u001b[0m df_cleaned \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhistorical_data\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    269\u001b[0m df_cleaned[\u001b[39m'\u001b[39m\u001b[39mCluster\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df_cleaned\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mmap(result)\n",
      "File \u001b[0;32m~/Documents/GitHub/Portfolio_clustering_project/Code/PyFolioCC.py:109\u001b[0m, in \u001b[0;36mPyFolioCC.apply_SPONGE\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[39m\u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[39m----------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[39mIDEA: Given a correlation matrix obtained from a database and \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39m----------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[39m## We respect the format imposed by signet. To do this, we need to change the type of the A_pos and A_neg matrices, which cannot remain dataframes\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m A_pos, A_neg \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcorrelation_matrix\u001b[39m.\u001b[39mapplymap(\u001b[39mlambda\u001b[39;00m x: x \u001b[39mif\u001b[39;00m x \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcorlation_matrix\u001b[39m.\u001b[39mapplymap(\u001b[39mlambda\u001b[39;00m x: \u001b[39mabs\u001b[39m(x) \u001b[39mif\u001b[39;00m x \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m)\n\u001b[1;32m    111\u001b[0m data \u001b[39m=\u001b[39m (sparse\u001b[39m.\u001b[39mcsc_matrix(A_pos\u001b[39m.\u001b[39mvalues), sparse\u001b[39m.\u001b[39mcsc_matrix(A_neg\u001b[39m.\u001b[39mvalues))\n\u001b[1;32m    113\u001b[0m cluster \u001b[39m=\u001b[39m Cluster(data)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PyFolioCC' object has no attribute 'corlation_matrix'"
     ]
    }
   ],
   "source": [
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "\n",
    "from PyFolioCC import PyFolioCC \n",
    "\n",
    "historical_data = df_cleaned\n",
    "lookback_window = [0, 50]\n",
    "evaluation_window = 1\n",
    "number_of_clusters = 38\n",
    "clustering_method = 'SPONGE'\n",
    "sigma = 0.01\n",
    "\n",
    "portfolio = PyFolioCC(historical_data=historical_data, lookback_window=lookback_window, evaluation_window=evaluation_window, number_of_clusters=number_of_clusters, sigma=sigma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
